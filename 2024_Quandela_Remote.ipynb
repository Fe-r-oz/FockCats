{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUANDELA REMOTE CHALLANGE - TEAM FOCKCATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import perceval as pcvl\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from perceval.components.unitary_components import PS, BS, PERM\n",
    "from perceval.components.port import Port, Encoding\n",
    "from perceval.utils import Encoding, PostSelect, Matrix\n",
    "from perceval.components import Unitary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The CZ gate in reference [5] - as a warm-up to the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"675.0\" height=\"406.25\" viewBox=\"-45.0 0 540.0 325.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25 L25,25\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75 L25,75\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125 L25,125\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175 L25,175\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M28,75 L72,125\" stroke=\"white\" stroke-width=\"6\" fill=\"none\" />\n",
       "<path d=\"M25,75 L28,75 L72,125 L75,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M28,125 L72,75\" stroke=\"white\" stroke-width=\"6\" fill=\"none\" />\n",
       "<path d=\"M25,125 L28,125 L72,75 L75,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,25 L75,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M75,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M80,140 L89,140 L103,110 L94,110 L80,140 L89,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"97\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=pi</text>\n",
       "<path d=\"M25,275 L75,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M30,290 L39,290 L53,260 L44,260 L30,290 L39,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"47\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=pi</text>\n",
       "<path d=\"M28,175 L72,225\" stroke=\"white\" stroke-width=\"6\" fill=\"none\" />\n",
       "<path d=\"M25,175 L28,175 L72,225 L75,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M125,125 L153,125 L172,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M178,144 L197,125 L225,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M125,175 L153,175 L172,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M178,156 L197,175 L225,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M150,143 L200,143 L200,157 L150,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"175\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"175\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=1.910786</text>\n",
       "<path d=\"M150,143 L200,143 L200,147 L150,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M193,150 L203,150 L203,160 L193,160 Z\" stroke=\"black\" fill=\"aquamarine\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"198\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">H</text>\n",
       "<path d=\"M75,225 L103,225 L122,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M128,244 L147,225 L175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M75,275 L103,275 L122,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M128,256 L147,275 L175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M100,243 L150,243 L150,257 L100,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"125\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"125\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=1.910786</text>\n",
       "<path d=\"M100,243 L150,243 L150,247 L100,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M143,250 L153,250 L153,260 L143,260 Z\" stroke=\"black\" fill=\"aquamarine\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"148\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">H</text>\n",
       "<path d=\"M175,225 L225,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,175 L272,225\" stroke=\"white\" stroke-width=\"6\" fill=\"none\" />\n",
       "<path d=\"M225,175 L228,175 L272,225 L275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,225 L272,175\" stroke=\"white\" stroke-width=\"6\" fill=\"none\" />\n",
       "<path d=\"M225,225 L228,225 L272,175 L275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M225,125 L275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M275,125 L303,125 L322,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M328,144 L347,125 L375,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M275,175 L303,175 L322,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M328,156 L347,175 L375,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M300,143 L350,143 L350,157 L300,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"325\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"325\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=10.655584</text>\n",
       "<path d=\"M300,143 L350,143 L350,147 L300,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M343,150 L353,150 L353,160 L343,160 Z\" stroke=\"black\" fill=\"aquamarine\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"348\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">H</text>\n",
       "<path d=\"M175,275 L275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M275,225 L303,225 L322,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M328,244 L347,225 L375,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M275,275 L303,275 L322,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M328,256 L347,275 L375,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M300,243 L350,243 L350,257 L300,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"325\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"325\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.615403</text>\n",
       "<path d=\"M300,243 L350,243 L350,247 L300,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M343,250 L353,250 L353,260 L343,260 Z\" stroke=\"black\" fill=\"aquamarine\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"348\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">H</text>\n",
       "<path d=\"M75,75 L375,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,75 L422,125\" stroke=\"white\" stroke-width=\"6\" fill=\"none\" />\n",
       "<path d=\"M375,75 L378,75 L422,125 L425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,125 L422,75\" stroke=\"white\" stroke-width=\"6\" fill=\"none\" />\n",
       "<path d=\"M375,125 L378,125 L422,75 L425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M75,25 L425,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M375,175 L425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M375,275 L425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M425,25 L440,25\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M425,75 L440,75\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M425,125 L440,125\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M425,175 L440,175\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M425,275 L440,275\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M107,175 C107,175,107,165,117,165 L125,165 L125,185 L117,185 C107,185,107,175,107,175 L107,175\" stroke-width=\"1\" stroke=\"black\" stroke-linejoin=\"miter\" fill=\"white\" />\n",
       "<text x=\"113\" y=\"191\" font-size=\"6\" text-anchor=\"middle\" font-style=\"italic\">[herald0]</text>\n",
       "<text x=\"117\" y=\"178\" font-size=\"7\" text-anchor=\"middle\">1</text>\n",
       "<path d=\"M7,275 C7,275,7,265,17,265 L25,265 L25,285 L17,285 C7,285,7,275,7,275 L7,275\" stroke-width=\"1\" stroke=\"black\" stroke-linejoin=\"miter\" fill=\"white\" />\n",
       "<text x=\"13\" y=\"291\" font-size=\"6\" text-anchor=\"middle\" font-style=\"italic\">[herald1]</text>\n",
       "<text x=\"17\" y=\"278\" font-size=\"7\" text-anchor=\"middle\">1</text>\n",
       "<path d=\"M-2,15 L10,15 L10,85 L-2,85 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"4\" y=\"27\" font-size=\"7\" text-anchor=\"middle\">0</text>\n",
       "<text x=\"4\" y=\"77\" font-size=\"7\" text-anchor=\"middle\">1</text>\n",
       "<text x=\"-2\" y=\"91\" font-size=\"6\" text-anchor=\"start\" font-style=\"italic\">[ctrl]</text>\n",
       "<path d=\"M-2,115 L10,115 L10,185 L-2,185 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"4\" y=\"127\" font-size=\"7\" text-anchor=\"middle\">2</text>\n",
       "<text x=\"4\" y=\"177\" font-size=\"7\" text-anchor=\"middle\">3</text>\n",
       "<text x=\"-2\" y=\"191\" font-size=\"6\" text-anchor=\"start\" font-style=\"italic\">[data]</text>\n",
       "<path d=\"M383,235 L375,235 L375,215 L383,215 C383,215,393,215,393,225 C393,235,383,235,383,235 L383,235\" stroke-width=\"1\" stroke=\"black\" stroke-linejoin=\"miter\" fill=\"white\" />\n",
       "<text x=\"388\" y=\"241\" font-size=\"6\" text-anchor=\"middle\" font-style=\"italic\">[herald0]</text>\n",
       "<text x=\"383\" y=\"228\" font-size=\"7\" text-anchor=\"middle\">1</text>\n",
       "<path d=\"M433,285 L425,285 L425,265 L433,265 C433,265,443,265,443,275 C443,285,433,285,433,285 L433,285\" stroke-width=\"1\" stroke=\"black\" stroke-linejoin=\"miter\" fill=\"white\" />\n",
       "<text x=\"438\" y=\"291\" font-size=\"6\" text-anchor=\"middle\" font-style=\"italic\">[herald1]</text>\n",
       "<text x=\"433\" y=\"278\" font-size=\"7\" text-anchor=\"middle\">1</text>\n",
       "<path d=\"M440,15 L452,15 L452,85 L440,85 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"446\" y=\"27\" font-size=\"7\" text-anchor=\"middle\">0</text>\n",
       "<text x=\"446\" y=\"77\" font-size=\"7\" text-anchor=\"middle\">1</text>\n",
       "<text x=\"452\" y=\"91\" font-size=\"6\" text-anchor=\"end\" font-style=\"italic\">[ctrl]</text>\n",
       "<path d=\"M440,115 L452,115 L452,185 L440,185 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"446\" y=\"127\" font-size=\"7\" text-anchor=\"middle\">2</text>\n",
       "<text x=\"446\" y=\"177\" font-size=\"7\" text-anchor=\"middle\">3</text>\n",
       "<text x=\"452\" y=\"191\" font-size=\"6\" text-anchor=\"end\" font-style=\"italic\">[data]</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x7f030d5f50c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create 4 modes for the photons that has been encoded for the CZ operation, while the first two modes represent the |1> state of the first qbit, and the last two modes represent the herald qbits.\n",
    "Knill_CZ = pcvl.Processor(\"SLOS\", 4)\n",
    "\n",
    "# Add the two pi-phase shifters to to the two system qubits\n",
    "Knill_CZ.add(0, PS(phi=np.pi))\n",
    "Knill_CZ.add(3, PS(phi=np.pi))\n",
    "\n",
    "# Add the beam splitters\n",
    "theta1 = 54.74 * 2 * np.pi / 180\n",
    "theta2 = 17.63 * 2 * np.pi / 180\n",
    "\n",
    "Knill_CZ.add((0, 2), BS.H(theta=theta1))\n",
    "Knill_CZ.add((2, 3), BS.H(theta=theta1))\n",
    "Knill_CZ.add((0, 2), BS.H(theta=-theta1))\n",
    "Knill_CZ.add((2, 3), BS.H(theta=theta2))\n",
    "\n",
    "# Add the heralds for the two beam splitters\n",
    "Knill_CZ.add_herald(2,1)\n",
    "Knill_CZ.add_herald(3,1)\n",
    "\n",
    "# Since the the modes 0 and 1 are the |1> state of the control and target qubits respectively, we need to permute the modes to make the CZ gate act on the correct modes\n",
    "CZ_gate = pcvl.Processor(\"SLOS\", 4)\n",
    "CZ_gate.add(1, PERM([1, 0]))\n",
    "CZ_gate.add(2, Knill_CZ)\n",
    "CZ_gate.add(1, PERM([1, 0]))\n",
    "\n",
    "# Add ports\n",
    "CZ_gate.add_port(0, Port(Encoding.DUAL_RAIL, 'ctrl'))\n",
    "CZ_gate.add_port(2, Port(Encoding.DUAL_RAIL, 'data'))\n",
    "\n",
    "pcvl.pdisplay(CZ_gate, recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  </th><th style=\"text-align: right;\">  00</th><th style=\"text-align: right;\">  01</th><th style=\"text-align: right;\">  10</th><th style=\"text-align: right;\">  11</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">00</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">01</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">11</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">   0</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance = 0.07406604842851158, fidelity = 0.9999999915267557\n"
     ]
    }
   ],
   "source": [
    "# Analyze the performance of the newly-created CZ gate\n",
    "processor = pcvl.Processor(\"SLOS\", 4)\n",
    "processor.add(2, pcvl.BS.H())\n",
    "processor.add(0, CZ_gate) # This is the gate that we created\n",
    "processor.add(2, pcvl.BS.H())\n",
    "\n",
    "# Everything else is the same\n",
    "states = {\n",
    "    pcvl.BasicState([1, 0, 1, 0]): \"00\",\n",
    "    pcvl.BasicState([1, 0, 0, 1]): \"01\",\n",
    "    pcvl.BasicState([0, 1, 1, 0]): \"10\",\n",
    "    pcvl.BasicState([0, 1, 0, 1]): \"11\"\n",
    "}\n",
    "\n",
    "ca = pcvl.algorithm.Analyzer(processor, states)\n",
    "\n",
    "truth_table = {\"00\": \"00\", \"01\": \"01\", \"10\": \"11\", \"11\": \"10\"}\n",
    "ca.compute(expected=truth_table)\n",
    "\n",
    "pcvl.pdisplay(ca)\n",
    "print(\n",
    "    f\"performance = {ca.performance}, fidelity = {ca.fidelity.real}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The CCZ gate in the Preceval library - serves as the bottom line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">   </th><th style=\"text-align: right;\">  000</th><th style=\"text-align: right;\">  010</th><th style=\"text-align: right;\">  100</th><th style=\"text-align: right;\">  110</th><th style=\"text-align: right;\">  001</th><th style=\"text-align: right;\">  011</th><th style=\"text-align: right;\">  101</th><th style=\"text-align: right;\">  111</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">000</td><td style=\"text-align: right;\">    1</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">010</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    1</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">100</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    1</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">110</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">001</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    1</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">011</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    1</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">101</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    1</td><td style=\"text-align: right;\">    0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">111</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    1</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance = 0.017559993780020683, fidelity = 1.0\n"
     ]
    }
   ],
   "source": [
    "processor = pcvl.Processor(\"SLOS\", 6)\n",
    "processor.add(4, pcvl.BS.H())\n",
    "processor.add(0, pcvl.catalog[\"postprocessed ccz\"].build_processor())\n",
    "processor.add(4, pcvl.BS.H())\n",
    "\n",
    "# Change the evaluation states to 3 qubits in dual-railed encoding\n",
    "states = {\n",
    "    pcvl.BasicState([1, 0, 1, 0, 1, 0]): \"000\",\n",
    "    pcvl.BasicState([1, 0, 0, 1, 1, 0]): \"010\",\n",
    "    pcvl.BasicState([0, 1, 1, 0, 1, 0]): \"100\",\n",
    "    pcvl.BasicState([0, 1, 0, 1, 1, 0]): \"110\",\n",
    "    pcvl.BasicState([1, 0, 1, 0, 0, 1]): \"001\",\n",
    "    pcvl.BasicState([1, 0, 0, 1, 0, 1]): \"011\",\n",
    "    pcvl.BasicState([0, 1, 1, 0, 0, 1]): \"101\",\n",
    "    pcvl.BasicState([0, 1, 0, 1, 0, 1]): \"111\"\n",
    "}\n",
    "\n",
    "ca = pcvl.algorithm.Analyzer(processor, states)\n",
    "\n",
    "# What is the truth table for the CCX (Tofolli) gate?\n",
    "truth_table = {\"000\": \"000\", \"010\": \"010\", \"100\": \"100\", \"110\": \"111\", \n",
    "               \"001\": \"001\", \"011\": \"011\", \"101\": \"101\", \"111\": \"110\"}\n",
    "ca.compute(expected=truth_table)\n",
    "\n",
    "pcvl.pdisplay(ca)\n",
    "print(\n",
    "    f\"performance = {ca.performance}, fidelity = {ca.fidelity.real}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"952.5\" height=\"781.25\" viewBox=\"-64.0 0 762.0 625.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25 L25,25\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75 L25,75\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125 L25,125\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175 L25,175\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225 L25,225\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275 L25,275\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M27,2 L623,2 L623,598 L27,598 Z\" stroke=\"black\" fill=\"lightblue\" stroke-dasharray=\"1,2\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"29\" y=\"605\" font-size=\"8\" text-anchor=\"start\">POSTPROCESSED CCZ</text>\n",
       "<path d=\"M25,25 L625,25\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,75 L625,75\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,125 L625,125\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,175 L625,175\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,225 L625,225\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,275 L625,275\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,325 L625,325\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,375 L625,375\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,425 L625,425\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,475 L625,475\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,525 L625,525\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,575 L625,575\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M30,5 L620,5 L620,595 L30,595 Z\" stroke=\"black\" fill=\"gold\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"325\" y=\"300\" font-size=\"10\" text-anchor=\"middle\">Unitary</text>\n",
       "<path d=\"M625,25 L640,25\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M625,75 L640,75\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M625,125 L640,125\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M625,175 L640,175\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M625,225 L640,225\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M625,275 L640,275\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M625,375 L640,375\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M625,425 L640,425\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M625,475 L640,475\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M625,525 L640,525\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M625,575 L640,575\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M-2,15 L10,15 L10,85 L-2,85 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"4\" y=\"27\" font-size=\"7\" text-anchor=\"middle\">0</text>\n",
       "<text x=\"4\" y=\"77\" font-size=\"7\" text-anchor=\"middle\">1</text>\n",
       "<text x=\"-2\" y=\"91\" font-size=\"6\" text-anchor=\"start\" font-style=\"italic\">[ctrl0]</text>\n",
       "<path d=\"M-2,115 L10,115 L10,185 L-2,185 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"4\" y=\"127\" font-size=\"7\" text-anchor=\"middle\">2</text>\n",
       "<text x=\"4\" y=\"177\" font-size=\"7\" text-anchor=\"middle\">3</text>\n",
       "<text x=\"-2\" y=\"191\" font-size=\"6\" text-anchor=\"start\" font-style=\"italic\">[ctrl1]</text>\n",
       "<path d=\"M-2,215 L10,215 L10,285 L-2,285 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"4\" y=\"227\" font-size=\"7\" text-anchor=\"middle\">4</text>\n",
       "<text x=\"4\" y=\"277\" font-size=\"7\" text-anchor=\"middle\">5</text>\n",
       "<text x=\"-2\" y=\"291\" font-size=\"6\" text-anchor=\"start\" font-style=\"italic\">[data]</text>\n",
       "<path d=\"M7,325 C7,325,7,315,17,315 L25,315 L25,335 L17,335 C7,335,7,325,7,325 L7,325\" stroke-width=\"1\" stroke=\"black\" stroke-linejoin=\"miter\" fill=\"white\" />\n",
       "<text x=\"13\" y=\"341\" font-size=\"6\" text-anchor=\"middle\" font-style=\"italic\">[herald0]</text>\n",
       "<text x=\"17\" y=\"328\" font-size=\"7\" text-anchor=\"middle\">0</text>\n",
       "<path d=\"M7,375 C7,375,7,365,17,365 L25,365 L25,385 L17,385 C7,385,7,375,7,375 L7,375\" stroke-width=\"1\" stroke=\"black\" stroke-linejoin=\"miter\" fill=\"white\" />\n",
       "<text x=\"13\" y=\"391\" font-size=\"6\" text-anchor=\"middle\" font-style=\"italic\">[herald1]</text>\n",
       "<text x=\"17\" y=\"378\" font-size=\"7\" text-anchor=\"middle\">0</text>\n",
       "<path d=\"M7,425 C7,425,7,415,17,415 L25,415 L25,435 L17,435 C7,435,7,425,7,425 L7,425\" stroke-width=\"1\" stroke=\"black\" stroke-linejoin=\"miter\" fill=\"white\" />\n",
       "<text x=\"13\" y=\"441\" font-size=\"6\" text-anchor=\"middle\" font-style=\"italic\">[herald2]</text>\n",
       "<text x=\"17\" y=\"428\" font-size=\"7\" text-anchor=\"middle\">0</text>\n",
       "<path d=\"M7,475 C7,475,7,465,17,465 L25,465 L25,485 L17,485 C7,485,7,475,7,475 L7,475\" stroke-width=\"1\" stroke=\"black\" stroke-linejoin=\"miter\" fill=\"white\" />\n",
       "<text x=\"13\" y=\"491\" font-size=\"6\" text-anchor=\"middle\" font-style=\"italic\">[herald3]</text>\n",
       "<text x=\"17\" y=\"478\" font-size=\"7\" text-anchor=\"middle\">0</text>\n",
       "<path d=\"M7,525 C7,525,7,515,17,515 L25,515 L25,535 L17,535 C7,535,7,525,7,525 L7,525\" stroke-width=\"1\" stroke=\"black\" stroke-linejoin=\"miter\" fill=\"white\" />\n",
       "<text x=\"13\" y=\"541\" font-size=\"6\" text-anchor=\"middle\" font-style=\"italic\">[herald4]</text>\n",
       "<text x=\"17\" y=\"528\" font-size=\"7\" text-anchor=\"middle\">0</text>\n",
       "<path d=\"M7,575 C7,575,7,565,17,565 L25,565 L25,585 L17,585 C7,585,7,575,7,575 L7,575\" stroke-width=\"1\" stroke=\"black\" stroke-linejoin=\"miter\" fill=\"white\" />\n",
       "<text x=\"13\" y=\"591\" font-size=\"6\" text-anchor=\"middle\" font-style=\"italic\">[herald5]</text>\n",
       "<text x=\"17\" y=\"578\" font-size=\"7\" text-anchor=\"middle\">0</text>\n",
       "<path d=\"M640,15 L652,15 L652,85 L640,85 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"646\" y=\"27\" font-size=\"7\" text-anchor=\"middle\">0</text>\n",
       "<text x=\"646\" y=\"77\" font-size=\"7\" text-anchor=\"middle\">1</text>\n",
       "<text x=\"652\" y=\"91\" font-size=\"6\" text-anchor=\"end\" font-style=\"italic\">[ctrl0]</text>\n",
       "<path d=\"M640,115 L652,115 L652,185 L640,185 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"646\" y=\"127\" font-size=\"7\" text-anchor=\"middle\">2</text>\n",
       "<text x=\"646\" y=\"177\" font-size=\"7\" text-anchor=\"middle\">3</text>\n",
       "<text x=\"652\" y=\"191\" font-size=\"6\" text-anchor=\"end\" font-style=\"italic\">[ctrl1]</text>\n",
       "<path d=\"M640,215 L652,215 L652,285 L640,285 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"646\" y=\"227\" font-size=\"7\" text-anchor=\"middle\">4</text>\n",
       "<text x=\"646\" y=\"277\" font-size=\"7\" text-anchor=\"middle\">5</text>\n",
       "<text x=\"652\" y=\"291\" font-size=\"6\" text-anchor=\"end\" font-style=\"italic\">[data]</text>\n",
       "<path d=\"M633,335 L625,335 L625,315 L633,315 C633,315,643,315,643,325 C643,335,633,335,633,335 L633,335\" stroke-width=\"1\" stroke=\"black\" stroke-linejoin=\"miter\" fill=\"white\" />\n",
       "<text x=\"638\" y=\"341\" font-size=\"6\" text-anchor=\"middle\" font-style=\"italic\">[herald0]</text>\n",
       "<text x=\"633\" y=\"328\" font-size=\"7\" text-anchor=\"middle\">0</text>\n",
       "<path d=\"M633,385 L625,385 L625,365 L633,365 C633,365,643,365,643,375 C643,385,633,385,633,385 L633,385\" stroke-width=\"1\" stroke=\"black\" stroke-linejoin=\"miter\" fill=\"white\" />\n",
       "<text x=\"638\" y=\"391\" font-size=\"6\" text-anchor=\"middle\" font-style=\"italic\">[herald1]</text>\n",
       "<text x=\"633\" y=\"378\" font-size=\"7\" text-anchor=\"middle\">0</text>\n",
       "<path d=\"M633,435 L625,435 L625,415 L633,415 C633,415,643,415,643,425 C643,435,633,435,633,435 L633,435\" stroke-width=\"1\" stroke=\"black\" stroke-linejoin=\"miter\" fill=\"white\" />\n",
       "<text x=\"638\" y=\"441\" font-size=\"6\" text-anchor=\"middle\" font-style=\"italic\">[herald2]</text>\n",
       "<text x=\"633\" y=\"428\" font-size=\"7\" text-anchor=\"middle\">0</text>\n",
       "<path d=\"M633,485 L625,485 L625,465 L633,465 C633,465,643,465,643,475 C643,485,633,485,633,485 L633,485\" stroke-width=\"1\" stroke=\"black\" stroke-linejoin=\"miter\" fill=\"white\" />\n",
       "<text x=\"638\" y=\"491\" font-size=\"6\" text-anchor=\"middle\" font-style=\"italic\">[herald3]</text>\n",
       "<text x=\"633\" y=\"478\" font-size=\"7\" text-anchor=\"middle\">0</text>\n",
       "<path d=\"M633,535 L625,535 L625,515 L633,515 C633,515,643,515,643,525 C643,535,633,535,633,535 L633,535\" stroke-width=\"1\" stroke=\"black\" stroke-linejoin=\"miter\" fill=\"white\" />\n",
       "<text x=\"638\" y=\"541\" font-size=\"6\" text-anchor=\"middle\" font-style=\"italic\">[herald4]</text>\n",
       "<text x=\"633\" y=\"528\" font-size=\"7\" text-anchor=\"middle\">0</text>\n",
       "<path d=\"M633,585 L625,585 L625,565 L633,565 C633,565,643,565,643,575 C643,585,633,585,633,585 L633,585\" stroke-width=\"1\" stroke=\"black\" stroke-linejoin=\"miter\" fill=\"white\" />\n",
       "<text x=\"638\" y=\"591\" font-size=\"6\" text-anchor=\"middle\" font-style=\"italic\">[herald5]</text>\n",
       "<text x=\"633\" y=\"578\" font-size=\"7\" text-anchor=\"middle\">0</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x7f030d5225f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What does the pre-defined CCZ gate look like?\n",
    "pcvl.pdisplay(pcvl.catalog[\"postprocessed ccz\"].build_processor(), recursive=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MatrixN([[ 1.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "          -1.45492529e-18+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j],\n",
       "         [ 0.00000000e+00+0.00000000e+00j,\n",
       "           1.00000000e+00-1.10422226e-17j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "          -1.86607692e-17-3.57986918e-16j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "          -3.42970653e-17+3.41273565e-16j,\n",
       "          -1.81312712e-17-2.21185450e-18j,\n",
       "           1.81312712e-17+2.21185450e-18j,\n",
       "          -2.23383234e-18-8.20707078e-18j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j],\n",
       "         [ 0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           1.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "          -1.45492529e-18+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j],\n",
       "         [ 0.00000000e+00+0.00000000e+00j,\n",
       "          -1.86607692e-17+3.57986918e-16j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           1.00000000e+00-9.77445910e-18j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "          -2.73581714e-17-3.55151353e-16j,\n",
       "           5.47475994e-18+6.90842142e-18j,\n",
       "          -1.81312712e-17-2.21185450e-18j,\n",
       "          -2.23383234e-18+8.20707078e-18j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j],\n",
       "         [ 0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           1.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "          -1.45492529e-18+0.00000000e+00j],\n",
       "         [ 0.00000000e+00+0.00000000e+00j,\n",
       "          -3.42970653e-17-3.41273565e-16j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "          -2.73581714e-17+3.55151353e-16j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           1.00000000e+00-1.10422226e-17j,\n",
       "          -9.62430437e-18+2.21185450e-18j,\n",
       "           5.47475994e-18+6.90842142e-18j,\n",
       "          -2.32879109e-17-2.21185450e-18j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j],\n",
       "         [ 0.00000000e+00+0.00000000e+00j,\n",
       "          -1.81312712e-17+3.45421071e-18j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           5.47475994e-18-6.90842142e-18j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "          -9.62430437e-18+3.45421071e-18j,\n",
       "           1.00000000e+00-1.77407931e-17j,\n",
       "          -1.87334335e-17-3.65440289e-16j,\n",
       "           9.02214214e-18+3.65440289e-16j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j],\n",
       "         [ 0.00000000e+00+0.00000000e+00j,\n",
       "           1.81312712e-17+3.45421071e-18j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "          -1.81312712e-17+3.45421071e-18j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           5.47475994e-18-6.90842142e-18j,\n",
       "          -1.87334335e-17+3.65440289e-16j,\n",
       "           1.00000000e+00+1.00147825e-17j,\n",
       "           9.02214214e-18-3.65440289e-16j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j],\n",
       "         [ 0.00000000e+00+0.00000000e+00j,\n",
       "          -2.23383234e-18+8.20707078e-18j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "          -2.23383234e-18-8.20707078e-18j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "          -2.32879109e-17+3.45421071e-18j,\n",
       "           9.02214214e-18-3.65440289e-16j,\n",
       "           9.02214214e-18+3.65440289e-16j,\n",
       "           1.00000000e+00-1.77407931e-17j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j],\n",
       "         [-1.45492529e-18+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           1.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j],\n",
       "         [ 0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "          -1.45492529e-18+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           1.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j],\n",
       "         [ 0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "          -1.45492529e-18+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           0.00000000e+00+0.00000000e+00j,\n",
       "           1.00000000e+00+0.00000000e+00j]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OK, I can't see anything inside. I'll copy their source code here. It is a unitary operator\n",
    "\n",
    "m = Matrix([[0.509824528533959, 0, 0, 0, 0, 0, 0, 0, 0, 0.860278414296864, 0, 0],\n",
    "                    [0, 0.509824528533959, 0, 0.321169327626332 + 0.556281593281541j, 0, 0, 0.330393705586394,\n",
    "                        - 0.165196852793197 - 0.286129342288294j, -0.165196852793197 + 0.286129342288294j, 0, 0, 0],\n",
    "                    [0, 0, 0.509824528533959, 0, 0, 0, 0, 0, 0, 0, 0.860278414296864, 0],\n",
    "                    [0, 0, 0, 0.509824528533959, 0, 0.321169327626332 + 0.556281593281541j, -0.165196852793197\n",
    "                        + 0.286129342288294j, 0.330393705586394, -0.165196852793197 - 0.286129342288294j, 0, 0, 0],\n",
    "                    [0, 0, 0, 0, 0.509824528533959, 0, 0, 0, 0, 0, 0, 0.860278414296864],\n",
    "                    [0, 0.321169327626332 + 0.556281593281541j, 0, 0, 0, 0.509824528533959, -0.165196852793197\n",
    "                        - 0.286129342288294j, -0.165196852793197 + 0.286129342288294j, 0.330393705586394, 0, 0, 0],\n",
    "                    [0, 0.330393705586394, 0, -0.165196852793197 - 0.286129342288294j, 0, -0.165196852793197\n",
    "                        + 0.286129342288294j, -0.509824528533959, 0, -0.321169327626332 + 0.556281593281541j, 0, 0, 0],\n",
    "                    [0, -0.165196852793197 + 0.286129342288294j, 0, 0.330393705586394, 0, -0.165196852793197\n",
    "                        - 0.286129342288294j, -0.321169327626332 + 0.556281593281541j, -0.509824528533959, 0, 0, 0, 0],\n",
    "                    [0, -0.165196852793197 - 0.286129342288294j, 0, -0.165196852793197 + 0.286129342288294j, 0,\n",
    "                        0.330393705586394, 0, -0.321169327626332 + 0.556281593281541j, -0.509824528533959, 0, 0, 0],\n",
    "                    [0.860278414296864, 0, 0, 0, 0, 0, 0, 0, 0, -0.509824528533959, 0, 0],\n",
    "                    [0, 0, 0.860278414296864, 0, 0, 0, 0, 0, 0, 0, -0.509824528533959, 0],\n",
    "                    [0, 0, 0, 0, 0.860278414296864, 0, 0, 0, 0, 0, 0, -0.509824528533959]])\n",
    "\n",
    "# m is indeed a unitary matrix, up to the numerical precision\n",
    "m_dagger = np.conjugate(m).T\n",
    "m_dagger_m = np.dot(m_dagger, m)\n",
    "m_dagger_m\n",
    "\n",
    "# I guess the whole point for this challenge is to optimize m to give better performance, while keeping the fidelity same as 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing the CCZ gate - Getting serious now!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to [6], `the maximum success probability is attained with minimal required resources!!`\n",
    "In the above examples, there 6 herald modes used, which makes the whole matrix 12x12. According to [6], the minimum number of 3 heralds are needed to reach perfect fidelity. Let's optimize using the case where 3, 4, 5, 6 heralds, corresponding to 9x9, 10x10, 11x11, 12x12 matrices, respectively.\n",
    "\n",
    "I will optimize the gate assuming that all heralds are |0>, because this minimizes the number of herald photons, the 3rd criteria for this challenge. **I think any case when a herald with |1> involved can be achieved by applying single-gates on the herald, which will not affect the overall success probability.** `Teammates, please think about this argument and see if it's a valid point!!`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, define the function to evaluate the matrix performance\n",
    "\n",
    "def evaluate_matrix(m): # This function don't check M. make sure we input a squre matrix!\n",
    "    dim = len(m) # figure out what is the dimension of the matrix\n",
    "    q, r = np.linalg.qr(m) # QR decomposition. given a matrix m, we obtain q which we're sure is unitary. This serves the input of the function\n",
    "\n",
    "    # The following part is essentially copied from the Quandela's source code\n",
    "    processor = pcvl.Processor(\"SLOS\", dim)\n",
    "    processor.add(4, pcvl.BS.H()) # This is because mode 4 & 5 are the target qubit for the CCZ gate\n",
    "    processor.add(0, Unitary(q))\n",
    "    processor.add(4, pcvl.BS.H())\n",
    "\n",
    "    # Post-selection. What does this mean? To be checked\n",
    "    # It seems that this line is present on any 'post-selection' gates in the Quandela's source code, and is not present on 'herald' gates. Why? to be checked\n",
    "    # The weird thing is that if I delete this line, the fidelity remains to be 1, and the performance almost doubles! Is this real? to be checked\n",
    "    processor.set_postselection(PostSelect(\"[0,1]==1 & [2,3]==1 & [4,5]==1\")) \n",
    "\n",
    "    processor.add_port(0, Port(Encoding.DUAL_RAIL, 'ctrl0'))\n",
    "    processor.add_port(2, Port(Encoding.DUAL_RAIL, 'ctrl1'))\n",
    "    processor.add_port(4, Port(Encoding.DUAL_RAIL, 'data'))\n",
    "\n",
    "    for i in range(6, dim):\n",
    "        processor.add_herald(i, 0)\n",
    "    \n",
    "    # Define the states and true tables for a CCNOT gate (after the Hadamard gates added on the data bit, CCZ gate has become a CCNOT gate and that's what we are going to evaluate)\n",
    "    states = {\n",
    "    pcvl.BasicState([1, 0, 1, 0, 1, 0]): \"000\",\n",
    "    pcvl.BasicState([1, 0, 0, 1, 1, 0]): \"010\",\n",
    "    pcvl.BasicState([0, 1, 1, 0, 1, 0]): \"100\",\n",
    "    pcvl.BasicState([0, 1, 0, 1, 1, 0]): \"110\",\n",
    "    pcvl.BasicState([1, 0, 1, 0, 0, 1]): \"001\",\n",
    "    pcvl.BasicState([1, 0, 0, 1, 0, 1]): \"011\",\n",
    "    pcvl.BasicState([0, 1, 1, 0, 0, 1]): \"101\",\n",
    "    pcvl.BasicState([0, 1, 0, 1, 0, 1]): \"111\"\n",
    "    }\n",
    "\n",
    "    ca = pcvl.algorithm.Analyzer(processor, states)\n",
    "\n",
    "    # What is the truth table for the CCNOT (Tofolli) gate?\n",
    "    truth_table = {\"000\": \"000\", \"010\": \"010\", \"100\": \"100\", \"110\": \"111\", \n",
    "                   \"001\": \"001\", \"011\": \"011\", \"101\": \"101\", \"111\": \"110\"}\n",
    "    ca.compute(expected=truth_table)\n",
    "    # pcvl.pdisplay(ca)\n",
    "    return ca.performance, ca.fidelity.real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1: Best Fitness = -5625383.713208989, Performance = 0.02253562569531889, Fidelity = 0.4374616061434754\n",
      "Generation 2: Best Fitness = -6348300.560057424, Performance = 0.0028710366240592075, Fidelity = 0.365169941123221\n",
      "Generation 3: Best Fitness = -6426827.478040812, Performance = 0.003149953715482573, Fidelity = 0.3573172490459652\n",
      "Generation 4: Best Fitness = -5577038.102341794, Performance = 0.00686650317965945, Fidelity = 0.4422961828993174\n",
      "Generation 5: Best Fitness = -6030793.464021394, Performance = 0.003406469234104434, Fidelity = 0.39692065019139133\n",
      "Generation 6: Best Fitness = -5854920.85362727, Performance = 0.009930664745347387, Fidelity = 0.41450790470660825\n",
      "Generation 7: Best Fitness = -5800041.4034426315, Performance = 0.024286240123207743, Fidelity = 0.4199958353694967\n",
      "Generation 8: Best Fitness = -4118242.5626295395, Performance = 0.07785045022128073, Fidelity = 0.5881756658865959\n",
      "Generation 9: Best Fitness = -5069766.764668733, Performance = 0.019138995757125923, Fidelity = 0.493023304394131\n",
      "Generation 10: Best Fitness = -4742439.575599578, Performance = 0.019394113706626002, Fidelity = 0.5257560230459285\n",
      "Generation 11: Best Fitness = -4383916.321959608, Performance = 0.030845374386071274, Fidelity = 0.5616083369586647\n",
      "Generation 12: Best Fitness = -4552959.859204714, Performance = 0.010041634777735139, Fidelity = 0.5447040040378939\n",
      "Generation 13: Best Fitness = -5259991.8709433805, Performance = 0.011003369635178235, Fidelity = 0.4740008019022923\n",
      "Generation 14: Best Fitness = -5359907.94618349, Performance = 0.021629048799051004, Fidelity = 0.46400918375260225\n",
      "Generation 15: Best Fitness = -4444316.170467915, Performance = 0.024055283482673415, Fidelity = 0.555568358897925\n",
      "Generation 16: Best Fitness = -3916446.847482679, Performance = 0.01627310913761353, Fidelity = 0.608355298978623\n",
      "Generation 17: Best Fitness = -3434363.879538444, Performance = 0.02205675296733931, Fidelity = 0.6565635899894027\n",
      "Generation 18: Best Fitness = -4174493.9471500427, Performance = 0.017816279935015177, Fidelity = 0.5825505874687158\n",
      "Generation 19: Best Fitness = -3725505.7449260186, Performance = 0.019259226810017845, Fidelity = 0.6274494062481714\n",
      "Generation 20: Best Fitness = -3865588.602044833, Performance = 0.060411119741218496, Fidelity = 0.613441079384397\n",
      "Generation 21: Best Fitness = -4074113.1361825434, Performance = 0.02799334074524532, Fidelity = 0.5925886583884049\n",
      "Generation 22: Best Fitness = -3124737.021182121, Performance = 0.044607865202171346, Fidelity = 0.6875262532739227\n",
      "Generation 23: Best Fitness = -3170155.635419304, Performance = 0.04623846446940457, Fidelity = 0.6829843902196051\n",
      "Generation 24: Best Fitness = -3063466.2655946244, Performance = 0.07841463265016063, Fidelity = 0.6936532950259049\n",
      "Generation 25: Best Fitness = -3198505.701734594, Performance = 0.18439423178219133, Fidelity = 0.6801492454323088\n",
      "Generation 26: Best Fitness = -3095145.196158309, Performance = 0.03581500096462681, Fidelity = 0.6904854445691682\n",
      "Generation 27: Best Fitness = -3008854.434254174, Performance = 0.020491155804690134, Fidelity = 0.6991145360834268\n",
      "Generation 28: Best Fitness = -3035901.7673146, Performance = 0.0219166035804126, Fidelity = 0.6964098013519364\n",
      "Generation 29: Best Fitness = -2639228.1662403718, Performance = 0.1130986047950075, Fidelity = 0.736077070277358\n",
      "Generation 30: Best Fitness = -2839030.638129659, Performance = 0.04992817982813317, Fidelity = 0.7160968862588543\n",
      "Generation 31: Best Fitness = -2745288.4984245715, Performance = 0.18241890213984543, Fidelity = 0.7254709677386407\n",
      "Generation 32: Best Fitness = -2757242.535626562, Performance = 0.19546193807246706, Fidelity = 0.7242755509754057\n",
      "Generation 33: Best Fitness = -2803012.851382805, Performance = 0.2018194997388883, Fidelity = 0.7196985130422198\n",
      "Generation 34: Best Fitness = -2846891.0655769124, Performance = 0.03454488546211291, Fidelity = 0.7153108588974233\n",
      "Generation 35: Best Fitness = -2801226.764933373, Performance = 0.04014466195501418, Fidelity = 0.7198772833620007\n",
      "Generation 36: Best Fitness = -2713350.445947511, Performance = 0.15141582475716112, Fidelity = 0.7286648039894241\n",
      "Generation 37: Best Fitness = -2626303.470070634, Performance = 0.030218113635072985, Fidelity = 0.737369622774823\n",
      "Generation 38: Best Fitness = -2624729.6647381126, Performance = 0.09490246209455305, Fidelity = 0.7375269386237266\n",
      "Generation 39: Best Fitness = -2549262.884395878, Performance = 0.1649069461855199, Fidelity = 0.745073546653466\n",
      "Generation 40: Best Fitness = -2580619.970196302, Performance = 0.1324864063705218, Fidelity = 0.7419378704939634\n",
      "Generation 41: Best Fitness = -2565025.7081241943, Performance = 0.1542982403256621, Fidelity = 0.7434972748893403\n",
      "Generation 42: Best Fitness = -2569933.5879712137, Performance = 0.13333053230594646, Fidelity = 0.7430065078723463\n",
      "Generation 43: Best Fitness = -2568365.489558657, Performance = 0.19965770112160133, Fidelity = 0.7431632513864331\n",
      "Generation 44: Best Fitness = -2613902.7574920584, Performance = 0.22972226729291773, Fidelity = 0.7386094945285269\n",
      "Generation 45: Best Fitness = -2589276.5140660782, Performance = 0.17706052388275537, Fidelity = 0.7410721715328683\n",
      "Generation 46: Best Fitness = -2604203.739211445, Performance = 0.10796541099704733, Fidelity = 0.7395795181134445\n",
      "Generation 47: Best Fitness = -2556193.5788918305, Performance = 0.21255673925178742, Fidelity = 0.7443804295540777\n",
      "Generation 48: Best Fitness = -2554418.6085775145, Performance = 0.19631349821641716, Fidelity = 0.7445579428287503\n",
      "Generation 49: Best Fitness = -2594269.5011478523, Performance = 0.33682185307884466, Fidelity = 0.7405727130633617\n",
      "Generation 50: Best Fitness = -2535284.354470196, Performance = 0.3198750810159163, Fidelity = 0.7464712446778994\n",
      "Generation 51: Best Fitness = -2537456.1158873313, Performance = 0.12283465819384465, Fidelity = 0.7462542655766087\n",
      "Generation 52: Best Fitness = -2541479.4441161337, Performance = 0.12463375416775545, Fidelity = 0.7458519309546324\n",
      "Generation 53: Best Fitness = -2522554.626342115, Performance = 0.32438913735077235, Fidelity = 0.7477442129766512\n",
      "Generation 54: Best Fitness = -2516570.2741823765, Performance = 0.31759185521604016, Fidelity = 0.7483426549899072\n",
      "Generation 55: Best Fitness = -2519135.2828971623, Performance = 0.34638588378115587, Fidelity = 0.7480861253244\n",
      "Generation 56: Best Fitness = -2547153.1483106967, Performance = 0.18951523562840356, Fidelity = 0.7452844956536947\n",
      "Generation 57: Best Fitness = -2363254.7067114487, Performance = 0.018138237924953015, Fidelity = 0.7636745111906172\n",
      "Generation 58: Best Fitness = -2528197.949993535, Performance = 0.3267992314407922, Fidelity = 0.7471798782014151\n",
      "Generation 59: Best Fitness = -2515864.260999825, Performance = 0.2747121445912097, Fidelity = 0.7484132991878729\n",
      "Generation 60: Best Fitness = -2523161.9949497366, Performance = 0.33280365705002657, Fidelity = 0.7476834677013693\n",
      "Generation 61: Best Fitness = -2498166.3912876183, Performance = 0.020209443265371413, Fidelity = 0.7501833406617949\n",
      "Generation 62: Best Fitness = -2517749.6070736395, Performance = 0.2586531003480943, Fidelity = 0.7482247806395357\n",
      "Generation 63: Best Fitness = -2522499.0365897613, Performance = 0.20036107874384237, Fidelity = 0.7477498959799451\n",
      "Generation 64: Best Fitness = -2528140.3185288124, Performance = 0.3620549009892876, Fidelity = 0.7471856060922177\n",
      "Generation 65: Best Fitness = -2526722.4337988147, Performance = 0.36403918301743676, Fidelity = 0.7473273925809355\n",
      "Generation 66: Best Fitness = -2529346.2122498555, Performance = 0.2983237455937449, Fidelity = 0.7470650804512688\n",
      "Generation 67: Best Fitness = -2521792.447105863, Performance = 0.2706606639534964, Fidelity = 0.7478204846287497\n",
      "Generation 68: Best Fitness = -2527061.9947144184, Performance = 0.26800632484227915, Fidelity = 0.7472935325222333\n",
      "Generation 69: Best Fitness = -2525662.285326151, Performance = 0.4136950169296424, Fidelity = 0.747433357772368\n",
      "Generation 70: Best Fitness = -2517833.7257547304, Performance = 0.5234818343231963, Fidelity = 0.7482161039426927\n",
      "Generation 71: Best Fitness = -2521858.719399214, Performance = 0.22654465381986413, Fidelity = 0.7478139015154248\n",
      "Generation 72: Best Fitness = -2533723.678917, Performance = 0.4345320191738495, Fidelity = 0.7466271975762808\n",
      "Generation 73: Best Fitness = -2508035.5693758084, Performance = 0.2580367883475166, Fidelity = 0.7491961850256308\n",
      "Generation 74: Best Fitness = -2518454.68211858, Performance = 0.2758566778419817, Fidelity = 0.7481542559314641\n",
      "Generation 75: Best Fitness = -2515825.219113447, Performance = 0.2946838118979371, Fidelity = 0.7484171834048434\n",
      "Generation 76: Best Fitness = -2499619.794498745, Performance = 0.12079152918847684, Fidelity = 0.7500378997585964\n",
      "Generation 77: Best Fitness = -2473972.2935658153, Performance = 0.12034144195985184, Fidelity = 0.7526026503019765\n",
      "Generation 78: Best Fitness = -2515263.396200184, Performance = 0.11811660591747046, Fidelity = 0.7484735422633757\n",
      "Generation 79: Best Fitness = -2515441.0722243055, Performance = 0.1746493528978433, Fidelity = 0.7484557181282165\n",
      "Generation 80: Best Fitness = -2509246.9800874917, Performance = 0.20231589268538636, Fidelity = 0.7490750996753581\n",
      "Generation 81: Best Fitness = -2499366.92373634, Performance = 0.1444374431460932, Fidelity = 0.7500631631889229\n",
      "Generation 82: Best Fitness = -2517613.503364915, Performance = 0.33906749996611674, Fidelity = 0.7482383105960085\n",
      "Generation 83: Best Fitness = -2496755.5814208915, Performance = 0.10220181824387536, Fidelity = 0.7503243396560926\n",
      "Generation 84: Best Fitness = -2501196.3740510033, Performance = 0.10558421197693238, Fidelity = 0.7498802570106877\n",
      "Generation 85: Best Fitness = -2467726.246376361, Performance = 0.06814360887599022, Fidelity = 0.753227307218755\n",
      "Generation 86: Best Fitness = -2489615.7814970855, Performance = 0.22414738434386394, Fidelity = 0.7510381977029071\n",
      "Generation 87: Best Fitness = -2491445.3003304116, Performance = 0.19301025074976383, Fidelity = 0.7508552769567081\n",
      "Generation 88: Best Fitness = -2507638.4029873875, Performance = 0.2149065825613714, Fidelity = 0.7492359447946787\n",
      "Generation 89: Best Fitness = -2513146.9986370048, Performance = 0.4150214335357095, Fidelity = 0.748684885114866\n",
      "Generation 90: Best Fitness = -2506452.8886971422, Performance = 0.3414098456338697, Fidelity = 0.7493543697204401\n",
      "Generation 91: Best Fitness = -2508228.3475832865, Performance = 0.5349618615932912, Fidelity = 0.7491766302798097\n",
      "Generation 92: Best Fitness = -2502573.5765416264, Performance = 0.42224759867190303, Fidelity = 0.7497422200982387\n",
      "Generation 93: Best Fitness = -2505207.5873409836, Performance = 0.37890930976251885, Fidelity = 0.7494788623565919\n",
      "Generation 94: Best Fitness = -2505000.441829067, Performance = 0.37977829201952157, Fidelity = 0.7494995760388012\n",
      "Generation 95: Best Fitness = -2507821.8486811933, Performance = 0.44463135771846746, Fidelity = 0.749217370500523\n",
      "Generation 96: Best Fitness = -2506662.1239400054, Performance = 0.41815815199419215, Fidelity = 0.7493333694478475\n",
      "Generation 97: Best Fitness = -2506217.533450178, Performance = 0.4191008945687026, Fidelity = 0.7493778275540877\n",
      "Generation 98: Best Fitness = -2504874.2612465983, Performance = 0.4238279330336011, Fidelity = 0.7495121500474071\n",
      "Generation 99: Best Fitness = -2506828.0911868387, Performance = 0.3340164100482485, Fidelity = 0.7493168568649061\n",
      "Generation 100: Best Fitness = -2506523.3244959335, Performance = 0.5116670737683715, Fidelity = 0.7493471558833329\n",
      "Generation 101: Best Fitness = -2503597.0274902103, Performance = 0.46116487155082303, Fidelity = 0.7496398360861074\n",
      "Generation 102: Best Fitness = -2502546.1943593435, Performance = 0.3736220663227922, Fidelity = 0.7497450069419993\n",
      "Generation 103: Best Fitness = -2505301.8690779563, Performance = 0.5043493611285196, Fidelity = 0.7494693087428432\n",
      "Generation 104: Best Fitness = -2505372.7308448763, Performance = 0.3095623958099052, Fidelity = 0.7494624173531166\n",
      "Generation 105: Best Fitness = -2458929.680757169, Performance = 0.06809476547974587, Fidelity = 0.7541069638295176\n",
      "Generation 106: Best Fitness = -2443821.6894593528, Performance = 0.058886398925219595, Fidelity = 0.7556177721676658\n",
      "Generation 107: Best Fitness = -2495201.2661511395, Performance = 0.11983194253634004, Fidelity = 0.7504797535529435\n",
      "Generation 108: Best Fitness = -2490581.7963504153, Performance = 0.1590099716938641, Fidelity = 0.7509416613549867\n",
      "Generation 109: Best Fitness = -2409320.9117336073, Performance = 0.05409725761036321, Fidelity = 0.7590678547293817\n",
      "Generation 110: Best Fitness = -2349095.176754944, Performance = 0.042367373285582884, Fidelity = 0.7650904399571323\n",
      "Generation 111: Best Fitness = -2487018.6628529574, Performance = 0.13015324420516697, Fidelity = 0.75129800356146\n",
      "Generation 112: Best Fitness = -2485356.8356598397, Performance = 0.1277516937960262, Fidelity = 0.7514641886823222\n",
      "Generation 113: Best Fitness = -2505443.0227887565, Performance = 0.37262367607234115, Fidelity = 0.7494553250974483\n",
      "Generation 114: Best Fitness = -2503449.4128679796, Performance = 0.6155470790605322, Fidelity = 0.749654443166123\n",
      "Generation 115: Best Fitness = -2503430.753762313, Performance = 0.3929266691148112, Fidelity = 0.7496565316970996\n",
      "Generation 116: Best Fitness = -2499270.490092388, Performance = 0.34202003773555134, Fidelity = 0.7500726089707235\n",
      "Generation 117: Best Fitness = -2497104.48338066, Performance = 0.2946526974384231, Fidelity = 0.7502892570092365\n",
      "Generation 118: Best Fitness = -2500389.2217304106, Performance = 0.29118731122861263, Fidelity = 0.7499607866396477\n",
      "Generation 119: Best Fitness = -2504047.8142257007, Performance = 0.14173188943490828, Fidelity = 0.7495950768455405\n",
      "Generation 120: Best Fitness = -2504681.8438742366, Performance = 0.28535408749273944, Fidelity = 0.7495315302584888\n",
      "Generation 121: Best Fitness = -2501962.7050261158, Performance = 0.32855326549690983, Fidelity = 0.7498034009441229\n",
      "Generation 122: Best Fitness = -2502232.66639753, Performance = 0.32165346278302076, Fidelity = 0.7497764117067842\n",
      "Generation 123: Best Fitness = -2502260.9830597807, Performance = 0.33972427205003475, Fidelity = 0.7497735619697499\n",
      "Generation 124: Best Fitness = -2505787.978722989, Performance = 0.41253170586544297, Fidelity = 0.7494207895959952\n",
      "Generation 125: Best Fitness = -2501054.3586296802, Performance = 0.2392295374457909, Fidelity = 0.7498943249074945\n",
      "Generation 126: Best Fitness = -2494374.9585014223, Performance = 0.21629096266347095, Fidelity = 0.7505622878588951\n",
      "Generation 127: Best Fitness = -2504147.000592623, Performance = 0.39885183393785095, Fidelity = 0.7495849010889037\n",
      "Generation 128: Best Fitness = -2505109.02570499, Performance = 0.20455255046202314, Fidelity = 0.7494888928769505\n",
      "Generation 129: Best Fitness = -2504934.268106428, Performance = 0.47044087616592134, Fidelity = 0.7495061027484811\n",
      "Generation 130: Best Fitness = -2504120.001795615, Performance = 0.22055181682370495, Fidelity = 0.7495877792686216\n",
      "Generation 131: Best Fitness = -2491817.319906784, Performance = 0.04963552003290547, Fidelity = 0.7508182183738016\n",
      "Generation 132: Best Fitness = -2476062.6537108067, Performance = 0.03488700756926028, Fidelity = 0.7523936997419117\n",
      "Generation 133: Best Fitness = -2506193.087566307, Performance = 0.3086784207586247, Fidelity = 0.7493803825649485\n",
      "Generation 134: Best Fitness = -2505431.53918798, Performance = 0.6001220859192812, Fidelity = 0.7494562459591161\n",
      "Generation 135: Best Fitness = -2502446.5713282675, Performance = 0.41027757710955676, Fidelity = 0.7497549325895961\n",
      "Generation 136: Best Fitness = -2505251.4868725813, Performance = 0.36488167226758506, Fidelity = 0.7494744864310696\n",
      "Generation 137: Best Fitness = -2505199.560471747, Performance = 0.24708879118106128, Fidelity = 0.7494797968640341\n",
      "Generation 138: Best Fitness = -2479757.38763929, Performance = 0.10861495544265103, Fidelity = 0.7520241526211155\n",
      "Generation 139: Best Fitness = -2459821.6856805286, Performance = 0.12122913331204208, Fidelity = 0.7540177102028138\n",
      "Generation 140: Best Fitness = -2474908.401206286, Performance = 0.20634967377770094, Fidelity = 0.7525089535296976\n",
      "Generation 141: Best Fitness = -2456600.642107413, Performance = 0.14108231677287336, Fidelity = 0.7543397947069419\n",
      "Generation 142: Best Fitness = -2485316.0726546436, Performance = 0.19717635595413618, Fidelity = 0.7514681955581797\n",
      "Generation 143: Best Fitness = -2488811.0202909755, Performance = 0.20696947156598755, Fidelity = 0.7511186910014309\n",
      "Generation 144: Best Fitness = -2471873.901908092, Performance = 0.09251553262798397, Fidelity = 0.7528125172936582\n",
      "Generation 145: Best Fitness = -2463302.7369964994, Performance = 0.17580376737832026, Fidelity = 0.7536695504965827\n",
      "Generation 146: Best Fitness = -2449169.7359164567, Performance = 0.16329190222174617, Fidelity = 0.7550828631164521\n",
      "Generation 147: Best Fitness = -2447487.3093316546, Performance = 0.15057884991545098, Fidelity = 0.7552511184879847\n",
      "Generation 148: Best Fitness = -2405008.375915959, Performance = 0.09359726986856429, Fidelity = 0.7594990688111343\n",
      "Generation 149: Best Fitness = -2317176.940021863, Performance = 0.05333569808809937, Fidelity = 0.7682822526621156\n",
      "Generation 150: Best Fitness = -2298400.803429333, Performance = 0.041797936271479735, Fidelity = 0.7701598778591304\n",
      "Generation 151: Best Fitness = -2252492.4997259816, Performance = 0.041781510299979445, Fidelity = 0.7747507082458915\n",
      "Generation 152: Best Fitness = -2248795.56233844, Performance = 0.04131047226520309, Fidelity = 0.7751204024556837\n",
      "Generation 153: Best Fitness = -2200847.352835093, Performance = 0.05635223650737966, Fidelity = 0.7799152083642542\n",
      "Generation 154: Best Fitness = -2092143.91824686, Performance = 0.01950353070961284, Fidelity = 0.7907855886717833\n",
      "Generation 155: Best Fitness = -2058129.0057438028, Performance = 0.020489373542404314, Fidelity = 0.7941870789362462\n",
      "Generation 156: Best Fitness = -2051168.503947513, Performance = 0.014438561745951728, Fidelity = 0.794883135166687\n",
      "Generation 157: Best Fitness = -1664525.3610853974, Performance = 0.016913420520551805, Fidelity = 0.8335474469780397\n",
      "Generation 158: Best Fitness = -1867831.6529369284, Performance = 0.010203158909820584, Fidelity = 0.8132168245031483\n",
      "Generation 159: Best Fitness = -1751525.0144619145, Performance = 0.003935036496731593, Fidelity = 0.824847494618772\n",
      "Generation 160: Best Fitness = -1746634.8843294755, Performance = 0.006719732890815303, Fidelity = 0.8253365048473196\n",
      "Generation 161: Best Fitness = -1690039.9095170682, Performance = 0.013976742968938857, Fidelity = 0.8309959950715502\n",
      "Generation 162: Best Fitness = -1295089.2405216873, Performance = 0.006444466976729435, Fidelity = 0.8704910695033643\n",
      "Generation 163: Best Fitness = -1444453.698632703, Performance = 0.02791845899147083, Fidelity = 0.8555546022182707\n",
      "Generation 164: Best Fitness = -1203991.0903236468, Performance = 0.012384599059353176, Fidelity = 0.8796008785830363\n",
      "Generation 165: Best Fitness = -1078993.9445070561, Performance = 0.004887977584638763, Fidelity = 0.8921006006613168\n",
      "Generation 166: Best Fitness = -1250428.7936216395, Performance = 0.009537519354678552, Fidelity = 0.8749571111003167\n",
      "Generation 167: Best Fitness = -819118.0714487002, Performance = 0.008601830011502467, Fidelity = 0.9180881842533\n",
      "Generation 168: Best Fitness = -645930.4368699933, Performance = 0.002294989785241569, Fidelity = 0.9354069540180109\n",
      "Generation 169: Best Fitness = -523823.91407183424, Performance = 0.0021582515241658894, Fidelity = 0.947617606434565\n",
      "Generation 170: Best Fitness = -903746.3145723669, Performance = 0.005956061966436127, Fidelity = 0.9096253625867013\n",
      "Generation 171: Best Fitness = -699580.6117414457, Performance = 0.021459126168468106, Fidelity = 0.9300419173667293\n",
      "Generation 172: Best Fitness = -635169.6656139133, Performance = 0.01775170926891931, Fidelity = 0.9364830156868994\n",
      "Generation 173: Best Fitness = -507001.6457165511, Performance = 0.012255074891836987, Fidelity = 0.94929982317327\n",
      "Generation 174: Best Fitness = -674031.5001850429, Performance = 0.016357142846013018, Fidelity = 0.9325968336243529\n",
      "Generation 175: Best Fitness = -586562.2589100626, Performance = 0.016088232320644675, Fidelity = 0.9413437580207614\n",
      "Generation 176: Best Fitness = -607763.1966200628, Performance = 0.005653818600974784, Fidelity = 0.9392236746841751\n",
      "Generation 177: Best Fitness = -525149.7083605621, Performance = 0.01006640688641232, Fidelity = 0.9474850190975369\n",
      "Generation 178: Best Fitness = -636354.4003607928, Performance = 0.018336117358402695, Fidelity = 0.9363645416278034\n",
      "Generation 179: Best Fitness = -606165.7481705195, Performance = 0.013314902964971953, Fidelity = 0.9393834118680451\n",
      "Generation 180: Best Fitness = -617285.1782105254, Performance = 0.003283578909043374, Fidelity = 0.9382714788953685\n",
      "Generation 181: Best Fitness = -473998.41822291433, Performance = 0.007148445689378141, Fidelity = 0.9526001510292629\n",
      "Generation 182: Best Fitness = -500977.24472207995, Performance = 0.011107413942387562, Fidelity = 0.9499022644203781\n",
      "Generation 183: Best Fitness = -482004.0290859024, Performance = 0.011657279746366262, Fidelity = 0.95179958543413\n",
      "Generation 184: Best Fitness = -365368.7250145294, Performance = 0.0033555100278584585, Fidelity = 0.963463124143037\n",
      "Generation 185: Best Fitness = -321128.8107751497, Performance = 0.003396903098688637, Fidelity = 0.9678871155255819\n",
      "Generation 186: Best Fitness = -319620.5017474025, Performance = 0.003343165353834905, Fidelity = 0.9680379464820944\n",
      "Generation 187: Best Fitness = -314171.17834070476, Performance = 0.0027445000119867974, Fidelity = 0.9685828794214295\n",
      "Generation 188: Best Fitness = -287574.81741468067, Performance = 0.00831400516942633, Fidelity = 0.9712425099445268\n",
      "Generation 189: Best Fitness = -181645.47706191233, Performance = 0.012149532394278973, Fidelity = 0.9818354401442764\n",
      "Generation 190: Best Fitness = -199043.9656570803, Performance = 0.008267014569904266, Fidelity = 0.9800955951672774\n",
      "Generation 191: Best Fitness = -214603.12760705253, Performance = 0.0070002030885160955, Fidelity = 0.9785396802390917\n",
      "Generation 192: Best Fitness = -199130.5511395259, Performance = 0.016027555277251398, Fidelity = 0.9800869288584921\n",
      "Generation 193: Best Fitness = -235578.1209885498, Performance = 0.006395421313347806, Fidelity = 0.9764421815057237\n",
      "Generation 194: Best Fitness = -176077.8604552065, Performance = 0.002837219744919903, Fidelity = 0.9823922111172596\n",
      "Generation 195: Best Fitness = -210261.50312165247, Performance = 0.007556245309837289, Fidelity = 0.9789738421315894\n",
      "Generation 196: Best Fitness = -179011.90120674623, Performance = 0.009001246271939179, Fidelity = 0.9820988008780791\n",
      "Generation 197: Best Fitness = -147157.95191593896, Performance = 0.004046704570810863, Fidelity = 0.9852842007617015\n",
      "Generation 198: Best Fitness = -176897.9157751971, Performance = 0.008099778069765471, Fidelity = 0.9823102003227022\n",
      "Generation 199: Best Fitness = -157716.83043616856, Performance = 0.0073663083540582985, Fidelity = 0.9842283095900748\n",
      "Generation 200: Best Fitness = -230478.2961753149, Performance = 0.006919734228478332, Fidelity = 0.9769521634627343\n",
      "Generation 201: Best Fitness = -225648.98844958184, Performance = 0.012078127361865431, Fidelity = 0.9774350890769145\n",
      "Generation 202: Best Fitness = -225325.26088520966, Performance = 0.006744447668074117, Fidelity = 0.9774674671670314\n",
      "Generation 203: Best Fitness = -168447.45494446647, Performance = 0.005919356946483615, Fidelity = 0.9831552485861964\n",
      "Generation 204: Best Fitness = -155397.8881250593, Performance = 0.00894481746060827, Fidelity = 0.9844602022426766\n",
      "Generation 205: Best Fitness = -185008.52297469112, Performance = 0.013899439380251347, Fidelity = 0.9814991338030915\n",
      "Generation 206: Best Fitness = -259219.0810162182, Performance = 0.013220372735430449, Fidelity = 0.9740780786780054\n",
      "Generation 207: Best Fitness = -257587.51405057628, Performance = 0.012044144730126084, Fidelity = 0.9742412365507976\n",
      "Generation 208: Best Fitness = -235336.17023401294, Performance = 0.019569752145317032, Fidelity = 0.9764663634068466\n",
      "Generation 209: Best Fitness = -199810.67494803198, Performance = 0.029100408657511748, Fidelity = 0.9800189034047881\n",
      "Generation 210: Best Fitness = -219942.50328716828, Performance = 0.02987058966413623, Fidelity = 0.9780057198006935\n",
      "Generation 211: Best Fitness = -165861.3629763888, Performance = 0.007620320769950638, Fidelity = 0.9834138560820403\n",
      "Generation 212: Best Fitness = -185639.51189892215, Performance = 0.02971560383110391, Fidelity = 0.981436019094504\n",
      "Generation 213: Best Fitness = -158574.30880233186, Performance = 0.02461954505454423, Fidelity = 0.9841425445002218\n",
      "Generation 214: Best Fitness = -175478.59655906056, Performance = 0.023324460078852888, Fidelity = 0.9824521170196339\n",
      "Generation 215: Best Fitness = -171419.77100279662, Performance = 0.022339961088981536, Fidelity = 0.9828580005597592\n",
      "Generation 216: Best Fitness = -177149.9788402103, Performance = 0.01687848777810386, Fidelity = 0.9822849852374912\n",
      "Generation 217: Best Fitness = -166448.24898494, Performance = 0.015637391441191036, Fidelity = 0.9833551594641146\n",
      "Generation 218: Best Fitness = -221810.36112719547, Performance = 0.01238476626563857, Fidelity = 0.9778189515025142\n",
      "Generation 219: Best Fitness = -221832.0775082301, Performance = 0.012387382384523792, Fidelity = 0.9778167798617946\n",
      "Generation 220: Best Fitness = -171359.0446925365, Performance = 0.020947033630784956, Fidelity = 0.9828640745837127\n",
      "Generation 221: Best Fitness = -201767.35221030793, Performance = 0.00959709668548396, Fidelity = 0.9798232551818725\n",
      "Generation 222: Best Fitness = -168662.8965960185, Performance = 0.003247266513274938, Fidelity = 0.9831337070931316\n",
      "Generation 223: Best Fitness = -176357.09039995985, Performance = 0.01937530127324053, Fidelity = 0.9823642715847027\n",
      "Generation 224: Best Fitness = -193540.03001351963, Performance = 0.014313084015887044, Fidelity = 0.980645982685564\n",
      "Generation 225: Best Fitness = -198379.8853160845, Performance = 0.02497370932556034, Fidelity = 0.9801619864946822\n",
      "Generation 226: Best Fitness = -160788.2170595078, Performance = 0.015019881765041184, Fidelity = 0.9839211632741675\n",
      "Generation 227: Best Fitness = -179664.97089306833, Performance = 0.01535190611311733, Fidelity = 0.982033487558787\n",
      "Generation 228: Best Fitness = -210984.88657431, Performance = 0.025610700477849687, Fidelity = 0.9789014857318685\n",
      "Generation 229: Best Fitness = -201496.6973270896, Performance = 0.025162291883731213, Fidelity = 0.9798503051049992\n",
      "Generation 230: Best Fitness = -231106.2979618741, Performance = 0.019691964034818175, Fidelity = 0.9768893505118486\n",
      "Generation 231: Best Fitness = -153778.90015265174, Performance = 0.021407083614434764, Fidelity = 0.9846220885776512\n",
      "Generation 232: Best Fitness = -153410.6303176138, Performance = 0.02140975023024603, Fidelity = 0.9846589155584884\n",
      "Generation 233: Best Fitness = -153027.00940400967, Performance = 0.01894455383020556, Fidelity = 0.9846972801150452\n",
      "Generation 234: Best Fitness = -167980.58265147207, Performance = 0.01749876269472507, Fidelity = 0.9832019242360901\n",
      "Generation 235: Best Fitness = -198808.98558883477, Performance = 0.017524445727241694, Fidelity = 0.9801190839166708\n",
      "Generation 236: Best Fitness = -184061.36033209495, Performance = 0.016511927949139537, Fidelity = 0.9815938474548626\n",
      "Generation 237: Best Fitness = -177388.21116972098, Performance = 0.014902123553944692, Fidelity = 0.9822611639809044\n",
      "Generation 238: Best Fitness = -157037.39954965754, Performance = 0.01902422643117911, Fidelity = 0.9842962410208078\n",
      "Generation 239: Best Fitness = -194380.32853025338, Performance = 0.0179575867810117, Fidelity = 0.9805619491893879\n",
      "Generation 240: Best Fitness = -209779.2635329612, Performance = 0.01434559734954331, Fidelity = 0.9790220593011065\n",
      "Generation 241: Best Fitness = -183160.90678246567, Performance = 0.008353824420315013, Fidelity = 0.981683900967929\n",
      "Generation 242: Best Fitness = -147401.01657917362, Performance = 0.012632006691664682, Fidelity = 0.9852598857100759\n",
      "Generation 243: Best Fitness = -149396.14998644785, Performance = 0.0076510891339741476, Fidelity = 0.9850603773502661\n",
      "Generation 244: Best Fitness = -198427.10359468844, Performance = 0.01203474729596844, Fidelity = 0.9801572776057839\n",
      "Generation 245: Best Fitness = -134295.53743373347, Performance = 0.006062764123359896, Fidelity = 0.9865704401938625\n",
      "Generation 246: Best Fitness = -186032.96691535055, Performance = 0.02219459914628519, Fidelity = 0.9813966811138658\n",
      "Generation 247: Best Fitness = -178960.00816783597, Performance = 0.009861588389763897, Fidelity = 0.982103989321628\n",
      "Generation 248: Best Fitness = -194498.6642768857, Performance = 0.016985333544637115, Fidelity = 0.9805501165869779\n",
      "Generation 249: Best Fitness = -209691.84476237727, Performance = 0.01755754754730068, Fidelity = 0.9790307979662147\n",
      "Generation 250: Best Fitness = -236202.86057572011, Performance = 0.009051539888270383, Fidelity = 0.9763797048908881\n",
      "Generation 251: Best Fitness = -203239.2464155443, Performance = 0.023100174425514593, Fidelity = 0.9796760522582711\n",
      "Generation 252: Best Fitness = -199937.271632766, Performance = 0.015801828986656878, Fidelity = 0.9800062570348944\n",
      "Generation 253: Best Fitness = -148541.5518204078, Performance = 0.014036694170303458, Fidelity = 0.985145830781265\n",
      "Generation 254: Best Fitness = -147012.81764973208, Performance = 0.025022059088286128, Fidelity = 0.9852986932129677\n",
      "Generation 255: Best Fitness = -147859.02477516048, Performance = 0.023962291646542327, Fidelity = 0.9852140735601923\n",
      "Generation 256: Best Fitness = -136330.65953723429, Performance = 0.019172707925822333, Fidelity = 0.9863669148735686\n",
      "Generation 257: Best Fitness = -123412.08786029514, Performance = 0.018387280140187368, Fidelity = 0.9876587728266903\n",
      "Generation 258: Best Fitness = -154159.01599094374, Performance = 0.02371756387753439, Fidelity = 0.9845840746833417\n",
      "Generation 259: Best Fitness = -154289.9498783676, Performance = 0.018891609082981785, Fidelity = 0.9845709861205542\n",
      "Generation 260: Best Fitness = -107113.40220951349, Performance = 0.026319954859785735, Fidelity = 0.9892886334590938\n",
      "Generation 261: Best Fitness = -144391.68748381943, Performance = 0.019435487968041173, Fidelity = 0.9855608118161301\n",
      "Generation 262: Best Fitness = -115803.06896837585, Performance = 0.024553900638482173, Fidelity = 0.9884196685492618\n",
      "Generation 263: Best Fitness = -108540.52845330411, Performance = 0.01516901999336416, Fidelity = 0.9891459319856496\n",
      "Generation 264: Best Fitness = -124027.41949995347, Performance = 0.017727760046243712, Fidelity = 0.9875972403222446\n",
      "Generation 265: Best Fitness = -123237.15465789821, Performance = 0.017650899396246922, Fidelity = 0.9876762668833108\n",
      "Generation 266: Best Fitness = -103495.33024188816, Performance = 0.015373987440167906, Fidelity = 0.9896504516018237\n",
      "Generation 267: Best Fitness = -103889.5782515047, Performance = 0.015479936675144653, Fidelity = 0.9896110266949129\n",
      "Generation 268: Best Fitness = -123007.4950015765, Performance = 0.019173870755701386, Fidelity = 0.9876992313259716\n",
      "Generation 269: Best Fitness = -124676.0357771896, Performance = 0.021044174144257712, Fidelity = 0.9875323753781069\n",
      "Generation 270: Best Fitness = -110141.3808716998, Performance = 0.01964689612940247, Fidelity = 0.9889858422659339\n",
      "Generation 271: Best Fitness = -109998.09716034685, Performance = 0.019729224216659205, Fidelity = 0.9890001705547411\n",
      "Generation 272: Best Fitness = -106149.33188868618, Performance = 0.020653203720291537, Fidelity = 0.9893850461579277\n",
      "Generation 273: Best Fitness = -103858.1187557326, Performance = 0.02164238070901734, Fidelity = 0.989614166482046\n",
      "Generation 274: Best Fitness = -120089.71887806356, Performance = 0.021721803807967316, Fidelity = 0.9879910063903898\n",
      "Generation 275: Best Fitness = -109552.29383733815, Performance = 0.012362463960212376, Fidelity = 0.9890447582538022\n",
      "Generation 276: Best Fitness = -137500.5656595493, Performance = 0.022360900940060636, Fidelity = 0.9862499210731441\n",
      "Generation 277: Best Fitness = -131002.68500721209, Performance = 0.02599534565886575, Fidelity = 0.9868997055039331\n",
      "Generation 278: Best Fitness = -172038.56226004518, Performance = 0.025419525365346366, Fidelity = 0.9827961183544701\n",
      "Generation 279: Best Fitness = -143839.62140141288, Performance = 0.030633238582791517, Fidelity = 0.9856160072266201\n",
      "Generation 280: Best Fitness = -139561.3993963836, Performance = 0.029460998349289908, Fidelity = 0.9860438305993633\n",
      "Generation 281: Best Fitness = -136807.24455980625, Performance = 0.029848436994652675, Fidelity = 0.9863192456955824\n",
      "Generation 282: Best Fitness = -130532.94315136923, Performance = 0.0227005220051289, Fidelity = 0.9869466829843411\n",
      "Generation 283: Best Fitness = -160129.94482488002, Performance = 0.023698593249455484, Fidelity = 0.9839869818189187\n",
      "Generation 284: Best Fitness = -132121.57274445306, Performance = 0.03176328427495581, Fidelity = 0.9867878109622704\n",
      "Generation 285: Best Fitness = -108159.1252454149, Performance = 0.017947621180242054, Fidelity = 0.9891840695278373\n",
      "Generation 286: Best Fitness = -136990.3349669693, Performance = 0.025229219883825236, Fidelity = 0.9863009412740832\n",
      "Generation 287: Best Fitness = -129167.32377242012, Performance = 0.02089749716670846, Fidelity = 0.9870832467252608\n",
      "Generation 288: Best Fitness = -134589.8523958661, Performance = 0.015064661015123328, Fidelity = 0.9865409996957524\n",
      "Generation 289: Best Fitness = -119058.46550825845, Performance = 0.015412031077624535, Fidelity = 0.9880941380371431\n",
      "Generation 290: Best Fitness = -123268.52086391526, Performance = 0.014006299987107496, Fidelity = 0.9876731339073085\n",
      "Generation 291: Best Fitness = -121019.46748965797, Performance = 0.014084624699171489, Fidelity = 0.9878980391664095\n",
      "Generation 292: Best Fitness = -95349.21749278036, Performance = 0.021312394426143088, Fidelity = 0.9904650569383275\n",
      "Generation 293: Best Fitness = -109579.59145023124, Performance = 0.02355869271767229, Fidelity = 0.9890420172962842\n",
      "Generation 294: Best Fitness = -127568.22106340839, Performance = 0.029594522653447034, Fidelity = 0.9872431482991365\n",
      "Generation 295: Best Fitness = -114872.58540613117, Performance = 0.010241398444840977, Fidelity = 0.9885127312179884\n",
      "Generation 296: Best Fitness = -103603.37613859553, Performance = 0.016206426330155958, Fidelity = 0.9896396461797141\n",
      "Generation 297: Best Fitness = -87495.49586386609, Performance = 0.016552453428879933, Fidelity = 0.99125043386116\n",
      "Generation 298: Best Fitness = -114095.1393682059, Performance = 0.009640299294432856, Fidelity = 0.9885904764228801\n",
      "Generation 299: Best Fitness = -121104.02980150045, Performance = 0.019979136614824672, Fidelity = 0.9878895770407133\n",
      "Generation 300: Best Fitness = -88607.7552786313, Performance = 0.008230867876170425, Fidelity = 0.991139216241269\n",
      "Generation 301: Best Fitness = -113641.67453639714, Performance = 0.02554173434139032, Fidelity = 0.9886358070046259\n",
      "Generation 302: Best Fitness = -103664.22345290617, Performance = 0.029459063410287305, Fidelity = 0.989633548195646\n",
      "Generation 303: Best Fitness = -101441.39838356778, Performance = 0.02887832389043826, Fidelity = 0.9898558312833193\n",
      "Generation 304: Best Fitness = -124611.04897975097, Performance = 0.030548740580509035, Fidelity = 0.9875388645532843\n",
      "Generation 305: Best Fitness = -107166.33066520798, Performance = 0.01200545509591436, Fidelity = 0.9892833549280241\n",
      "Generation 306: Best Fitness = -93202.347114457, Performance = 0.01157391850915562, Fidelity = 0.9906797537146358\n",
      "Generation 307: Best Fitness = -109646.39477302517, Performance = 0.015378775487870085, Fidelity = 0.989035345143922\n",
      "Generation 308: Best Fitness = -144275.22805490805, Performance = 0.02724159582094895, Fidelity = 0.9855724499529134\n",
      "Generation 309: Best Fitness = -86883.90791953498, Performance = 0.02760790251458222, Fidelity = 0.991311581600144\n",
      "Generation 310: Best Fitness = -114276.42008113662, Performance = 0.022531502194132358, Fidelity = 0.9885723354603841\n",
      "Generation 311: Best Fitness = -101732.29401855209, Performance = 0.017208923800275173, Fidelity = 0.989826753389221\n",
      "Generation 312: Best Fitness = -101758.73567290709, Performance = 0.016065492555133322, Fidelity = 0.9898241103672167\n",
      "Generation 313: Best Fitness = -98814.76833325379, Performance = 0.01977236744058588, Fidelity = 0.9901185033943072\n",
      "Generation 314: Best Fitness = -93743.501309801, Performance = 0.010552228637717216, Fidelity = 0.9906256393167913\n",
      "Generation 315: Best Fitness = -124773.99204767027, Performance = 0.01886828166863422, Fidelity = 0.9875225819269513\n",
      "Generation 316: Best Fitness = -78768.58031423019, Performance = 0.013552922559988566, Fidelity = 0.9921231284156544\n",
      "Generation 317: Best Fitness = -78358.38855289623, Performance = 0.013171352765067595, Fidelity = 0.9921641479733576\n",
      "Generation 318: Best Fitness = -102043.63284630261, Performance = 0.012843605286921717, Fidelity = 0.9897956238717645\n",
      "Generation 319: Best Fitness = -86976.50828399757, Performance = 0.013015833338320721, Fidelity = 0.9913023361557669\n",
      "Generation 320: Best Fitness = -63449.07823289351, Performance = 0.013541232787112488, Fidelity = 0.9936550786354779\n",
      "Generation 321: Best Fitness = -101690.22433198821, Performance = 0.020431137797559704, Fidelity = 0.9898309571356634\n",
      "Generation 322: Best Fitness = -126430.33530208032, Performance = 0.019753757168460524, Fidelity = 0.9873569467160348\n",
      "Generation 323: Best Fitness = -100406.48297600892, Performance = 0.021635491824443853, Fidelity = 0.9899593300669073\n",
      "Generation 324: Best Fitness = -99671.25106441193, Performance = 0.021640234898648573, Fidelity = 0.9900328532533239\n",
      "Generation 325: Best Fitness = -99265.55396502522, Performance = 0.018860365193070425, Fidelity = 0.9900734257431323\n",
      "Generation 326: Best Fitness = -87464.80760534055, Performance = 0.01743975855151932, Fidelity = 0.9912535017997074\n",
      "Generation 327: Best Fitness = -105962.46388694963, Performance = 0.007909586518577637, Fidelity = 0.9894037457017185\n",
      "Generation 328: Best Fitness = -111373.91528318128, Performance = 0.02082450393510308, Fidelity = 0.9888625876471779\n",
      "Generation 329: Best Fitness = -108924.90453782135, Performance = 0.018075337247273452, Fidelity = 0.9891074914708806\n",
      "Generation 330: Best Fitness = -106173.91018876637, Performance = 0.02568943687206721, Fidelity = 0.9893825832916865\n",
      "Generation 331: Best Fitness = -84674.57059148802, Performance = 0.026136602165533564, Fidelity = 0.991532516804249\n",
      "Generation 332: Best Fitness = -111750.8756060774, Performance = 0.03193722127040027, Fidelity = 0.988824880502171\n",
      "Generation 333: Best Fitness = -91716.47624743474, Performance = 0.02490502421937358, Fidelity = 0.9908283274702323\n",
      "Generation 334: Best Fitness = -82968.91975010229, Performance = 0.019248529808520078, Fidelity = 0.99170308877646\n",
      "Generation 335: Best Fitness = -92188.84700092381, Performance = 0.025259284305357496, Fidelity = 0.9907810900406233\n",
      "Generation 336: Best Fitness = -87041.14082961365, Performance = 0.03321787498604686, Fidelity = 0.9912958526991636\n",
      "Generation 337: Best Fitness = -104224.83292368673, Performance = 0.01929439535314098, Fidelity = 0.989577497413236\n",
      "Generation 338: Best Fitness = -86433.49449975962, Performance = 0.018002524422616163, Fidelity = 0.9913566325474996\n",
      "Generation 339: Best Fitness = -59744.289362269155, Performance = 0.014262214954263991, Fidelity = 0.9940255568015581\n",
      "Generation 340: Best Fitness = -49481.14338132299, Performance = 0.014457640589442192, Fidelity = 0.9950518712042271\n",
      "Generation 341: Best Fitness = -64542.19392443842, Performance = 0.01586716391241292, Fidelity = 0.9935457647403922\n",
      "Generation 342: Best Fitness = -48548.41865923589, Performance = 0.015552022411797971, Fidelity = 0.995145142582054\n",
      "Generation 343: Best Fitness = -101380.53316719165, Performance = 0.020390640475517485, Fidelity = 0.9898619262926404\n",
      "Generation 344: Best Fitness = -85679.05196150826, Performance = 0.02027699062063279, Fidelity = 0.9914320745268586\n",
      "Generation 345: Best Fitness = -93900.71823336776, Performance = 0.019291498132948642, Fidelity = 0.9906099088851651\n",
      "Generation 346: Best Fitness = -95443.42293002014, Performance = 0.0205597311769333, Fidelity = 0.9904556371472668\n",
      "Generation 347: Best Fitness = -77365.69547743653, Performance = 0.01420230117090121, Fidelity = 0.9922634162499552\n",
      "Generation 348: Best Fitness = -91623.23999901315, Performance = 0.02732285923916613, Fidelity = 0.9908376486772394\n",
      "Generation 349: Best Fitness = -108743.87288397682, Performance = 0.02529433512539707, Fidelity = 0.9891255874172672\n",
      "Generation 350: Best Fitness = -99249.60573010046, Performance = 0.027235735466029122, Fidelity = 0.9900750121912545\n",
      "Generation 351: Best Fitness = -101932.10232393348, Performance = 0.02291694727168725, Fidelity = 0.9898067668506594\n",
      "Generation 352: Best Fitness = -101452.95942938095, Performance = 0.027855462845633595, Fidelity = 0.9898546762015991\n",
      "Generation 353: Best Fitness = -90965.37471270589, Performance = 0.02923710507479629, Fidelity = 0.9909034332916243\n",
      "Generation 354: Best Fitness = -84213.41020458737, Performance = 0.025505708358199323, Fidelity = 0.9915786334738329\n",
      "Generation 355: Best Fitness = -108757.9290601096, Performance = 0.019644650539856007, Fidelity = 0.9891241874493385\n",
      "Generation 356: Best Fitness = -100719.01068248737, Performance = 0.024468306156470783, Fidelity = 0.9899280744634451\n",
      "Generation 357: Best Fitness = -83581.46893913217, Performance = 0.028667023215041897, Fidelity = 0.9916418244390636\n",
      "Generation 358: Best Fitness = -89849.51254696706, Performance = 0.022884697991506095, Fidelity = 0.9910150258606053\n",
      "Generation 359: Best Fitness = -105827.19014976331, Performance = 0.02536518238464335, Fidelity = 0.9894172556198413\n",
      "Generation 360: Best Fitness = -126866.57641812364, Performance = 0.018276688115151346, Fidelity = 0.9873133240814995\n",
      "Generation 361: Best Fitness = -113824.68599248328, Performance = 0.02496970149649004, Fidelity = 0.9886175064310502\n",
      "Generation 362: Best Fitness = -98081.8539028259, Performance = 0.025537547650535185, Fidelity = 0.9901917890721698\n",
      "Generation 363: Best Fitness = -106496.24925255311, Performance = 0.03234810577948402, Fidelity = 0.9893503427266389\n",
      "Generation 364: Best Fitness = -84644.72829342149, Performance = 0.025582579390720762, Fidelity = 0.9915355015880785\n",
      "Generation 365: Best Fitness = -87108.09765295731, Performance = 0.01418248493506457, Fidelity = 0.9912891760522193\n",
      "Generation 366: Best Fitness = -80100.31493299472, Performance = 0.02966798608040526, Fidelity = 0.9919899388387144\n",
      "Generation 367: Best Fitness = -88557.36716416714, Performance = 0.028405532919488965, Fidelity = 0.9911442348780504\n",
      "Generation 368: Best Fitness = -70347.01419315484, Performance = 0.02512320575726267, Fidelity = 0.9929652734574788\n",
      "Generation 369: Best Fitness = -78265.85517601225, Performance = 0.025007101789584908, Fidelity = 0.992173389475297\n",
      "Generation 370: Best Fitness = -65329.46589354321, Performance = 0.01993366206066223, Fidelity = 0.9934670334769836\n",
      "Generation 371: Best Fitness = -77107.739793692, Performance = 0.022703745495487013, Fidelity = 0.9922892033168853\n",
      "Generation 372: Best Fitness = -61227.63294224421, Performance = 0.023925861436121392, Fidelity = 0.9938772127799141\n",
      "Generation 373: Best Fitness = -73317.64791530746, Performance = 0.015202428318157813, Fidelity = 0.9926682200060409\n",
      "Generation 374: Best Fitness = -55689.95754451337, Performance = 0.016329578819855934, Fidelity = 0.9944309879159698\n",
      "Generation 375: Best Fitness = -60196.311790904954, Performance = 0.022891105283637962, Fidelity = 0.9939803459298042\n",
      "Generation 376: Best Fitness = -58155.29963466432, Performance = 0.022320126440712282, Fidelity = 0.9941844477164071\n",
      "Generation 377: Best Fitness = -67877.74333569975, Performance = 0.023605486064023195, Fidelity = 0.993212202060944\n",
      "Generation 378: Best Fitness = -48819.42706649201, Performance = 0.021379167890945773, Fidelity = 0.9951180359141829\n",
      "Generation 379: Best Fitness = -48819.42706649201, Performance = 0.021379167890945773, Fidelity = 0.9951180359141829\n",
      "Generation 380: Best Fitness = -57241.83574069215, Performance = 0.021367339579442753, Fidelity = 0.9942757950585912\n",
      "Generation 381: Best Fitness = -54175.08967227385, Performance = 0.02044395395836239, Fidelity = 0.9945824705888187\n",
      "Generation 382: Best Fitness = -55243.51395174963, Performance = 0.02062997391994455, Fidelity = 0.9944756279748511\n",
      "Generation 383: Best Fitness = -75026.18811886357, Performance = 0.01798640719275352, Fidelity = 0.9924973632017065\n",
      "Generation 384: Best Fitness = -65219.197722992525, Performance = 0.01877490914180719, Fidelity = 0.9934780614527916\n",
      "Generation 385: Best Fitness = -68333.03409493974, Performance = 0.019384407500896417, Fidelity = 0.9931666772060985\n",
      "Generation 386: Best Fitness = -55812.117311640686, Performance = 0.016897595691292105, Fidelity = 0.9944187713712402\n",
      "Generation 387: Best Fitness = -70877.76945932987, Performance = 0.01999998578133972, Fidelity = 0.9929122030540812\n",
      "Generation 388: Best Fitness = -70230.48793721659, Performance = 0.021829640612810893, Fidelity = 0.9929769293766377\n",
      "Generation 389: Best Fitness = -73129.85399540619, Performance = 0.019348430079680214, Fidelity = 0.9926869952520293\n",
      "Generation 390: Best Fitness = -65138.79236991846, Performance = 0.012120804273592058, Fidelity = 0.9934861086422039\n",
      "Generation 391: Best Fitness = -62261.838626971556, Performance = 0.012136130632556872, Fidelity = 0.9937738040011722\n",
      "Generation 392: Best Fitness = -63023.11010230443, Performance = 0.011878407857906493, Fidelity = 0.9936976771113617\n",
      "Generation 393: Best Fitness = -59737.37932371801, Performance = 0.01344354413607461, Fidelity = 0.9940262486240841\n",
      "Generation 394: Best Fitness = -51389.01573777299, Performance = 0.014823948490900794, Fidelity = 0.9948610836022742\n",
      "Generation 395: Best Fitness = -81356.75416118918, Performance = 0.01572678843484798, Fidelity = 0.9918643088570926\n",
      "Generation 396: Best Fitness = -78312.80279123005, Performance = 0.02979465767943424, Fidelity = 0.9921686899262193\n",
      "Generation 397: Best Fitness = -73450.53419303271, Performance = 0.027069612529641605, Fidelity = 0.9926549195110842\n",
      "Generation 398: Best Fitness = -82271.26029282424, Performance = 0.019430400636942867, Fidelity = 0.9917728545403169\n",
      "Generation 399: Best Fitness = -95962.52941315391, Performance = 0.0233515334794301, Fidelity = 0.9904037237071511\n",
      "Generation 400: Best Fitness = -69539.25630146789, Performance = 0.019429007908353613, Fidelity = 0.9930460549408453\n",
      "Generation 401: Best Fitness = -78765.8410815368, Performance = 0.02242803370022169, Fidelity = 0.9921233934638126\n",
      "Generation 402: Best Fitness = -86823.75299676285, Performance = 0.02554681790156351, Fidelity = 0.9913175991535058\n",
      "Generation 403: Best Fitness = -84573.3809896169, Performance = 0.016712868497539436, Fidelity = 0.9915426451881698\n",
      "Generation 404: Best Fitness = -70566.34935431363, Performance = 0.012779402467588484, Fidelity = 0.9929433522851662\n",
      "Generation 405: Best Fitness = -68620.80662414295, Performance = 0.024007202157826694, Fidelity = 0.9931378953303835\n",
      "Generation 406: Best Fitness = -66359.54099124635, Performance = 0.019084678410114925, Fidelity = 0.993364026816197\n",
      "Generation 407: Best Fitness = -87626.77697011294, Performance = 0.02333670749503997, Fidelity = 0.9912372989662812\n",
      "Generation 408: Best Fitness = -72467.90478044437, Performance = 0.023303960874213322, Fidelity = 0.9927531862179947\n",
      "Generation 409: Best Fitness = -73095.1163528677, Performance = 0.020877245753823943, Fidelity = 0.9926904674874675\n",
      "Generation 410: Best Fitness = -89322.36948969189, Performance = 0.015714068131932754, Fidelity = 0.9910677473369627\n",
      "Generation 411: Best Fitness = -85667.50740563516, Performance = 0.02239599766327956, Fidelity = 0.9914332268634388\n",
      "Generation 412: Best Fitness = -82357.61337782285, Performance = 0.0242132498190759, Fidelity = 0.9917642144489679\n",
      "Generation 413: Best Fitness = -87389.3883248352, Performance = 0.018804831837229745, Fidelity = 0.9912610423626846\n",
      "Generation 414: Best Fitness = -74159.15571176544, Performance = 0.02201510912555417, Fidelity = 0.9925840624137143\n",
      "Generation 415: Best Fitness = -68333.82196834311, Performance = 0.021716878143949025, Fidelity = 0.9931665960862875\n",
      "Generation 416: Best Fitness = -72921.71173244376, Performance = 0.018931760771124, Fidelity = 0.9927078098949949\n",
      "Generation 417: Best Fitness = -62023.82138950943, Performance = 0.025962613639159728, Fidelity = 0.9937975918984354\n",
      "Generation 418: Best Fitness = -71045.62884759478, Performance = 0.018860146768094086, Fidelity = 0.9928954182550938\n",
      "Generation 419: Best Fitness = -80487.75151570342, Performance = 0.018046372039796307, Fidelity = 0.9919512068020576\n",
      "Generation 420: Best Fitness = -83046.42670692058, Performance = 0.018614190217993525, Fidelity = 0.9916953387151177\n",
      "Generation 421: Best Fitness = -92389.4018912035, Performance = 0.030667192850407376, Fidelity = 0.9907610291436868\n",
      "Generation 422: Best Fitness = -93379.82987690374, Performance = 0.020204641538145367, Fidelity = 0.9906619968076681\n",
      "Generation 423: Best Fitness = -101594.15744679101, Performance = 0.03647760010779904, Fidelity = 0.9898405477777208\n",
      "Generation 424: Best Fitness = -98217.83242457468, Performance = 0.019685022560328613, Fidelity = 0.99017819707252\n",
      "Generation 425: Best Fitness = -81700.72329844939, Performance = 0.027475340853367385, Fidelity = 0.9918299001948142\n",
      "Generation 426: Best Fitness = -83811.47222602773, Performance = 0.020683984498785876, Fidelity = 0.9916188320934127\n",
      "Generation 427: Best Fitness = -69501.71049455571, Performance = 0.03276193120876217, Fidelity = 0.9930497961886132\n",
      "Generation 428: Best Fitness = -68128.28828653907, Performance = 0.01986925441733901, Fidelity = 0.9931871513020917\n",
      "Generation 429: Best Fitness = -83706.98738996524, Performance = 0.030923168596860937, Fidelity = 0.9916292703378349\n",
      "Generation 430: Best Fitness = -57966.75840888856, Performance = 0.017478736544662497, Fidelity = 0.9942033066803746\n",
      "Generation 431: Best Fitness = -66737.50414205568, Performance = 0.018024642802712695, Fidelity = 0.9933262315611516\n",
      "Generation 432: Best Fitness = -61358.327635403366, Performance = 0.021200203383796083, Fidelity = 0.9938641460362563\n",
      "Generation 433: Best Fitness = -80798.65958969889, Performance = 0.021949807449262004, Fidelity = 0.9919201120912227\n",
      "Generation 434: Best Fitness = -74774.72353369667, Performance = 0.015298196194965771, Fidelity = 0.9925225123484341\n",
      "Generation 435: Best Fitness = -66066.435884501, Performance = 0.02231901174004761, Fidelity = 0.9933933340925382\n",
      "Generation 436: Best Fitness = -84500.29172763228, Performance = 0.025394685622040208, Fidelity = 0.9915499454325511\n",
      "Generation 437: Best Fitness = -81658.81676561853, Performance = 0.018060220093092286, Fidelity = 0.991834100263218\n",
      "Generation 438: Best Fitness = -88954.87918658483, Performance = 0.018369760691496404, Fidelity = 0.9911044937115808\n",
      "Generation 439: Best Fitness = -78009.90251119086, Performance = 0.014513143623850361, Fidelity = 0.9921989952357373\n",
      "Generation 440: Best Fitness = -87883.60807239915, Performance = 0.013904003581535427, Fidelity = 0.9912116252887565\n",
      "Generation 441: Best Fitness = -75095.40308381573, Performance = 0.007087465509771505, Fidelity = 0.9924904526041529\n",
      "Generation 442: Best Fitness = -89185.75410553075, Performance = 0.018688555481001023, Fidelity = 0.9910814059008914\n",
      "Generation 443: Best Fitness = -84198.12821131904, Performance = 0.007959193201241981, Fidelity = 0.9915801792196749\n",
      "Generation 444: Best Fitness = -65080.92618005474, Performance = 0.02144268870731706, Fidelity = 0.9934918859393058\n",
      "Generation 445: Best Fitness = -77282.09929176758, Performance = 0.018282380628372546, Fidelity = 0.9922717717884426\n",
      "Generation 446: Best Fitness = -90052.14938667942, Performance = 0.012406390987827972, Fidelity = 0.9909947726549411\n",
      "Generation 447: Best Fitness = -83498.9758507975, Performance = 0.018604756964685464, Fidelity = 0.9916500838101633\n",
      "Generation 448: Best Fitness = -82149.79905151008, Performance = 0.024336072890766287, Fidelity = 0.9917849957587761\n",
      "Generation 449: Best Fitness = -53717.71546096886, Performance = 0.020967766552641397, Fidelity = 0.9946282074861366\n",
      "Generation 450: Best Fitness = -56635.76384226322, Performance = 0.02291634337769111, Fidelity = 0.9943364006994303\n",
      "Generation 451: Best Fitness = -73503.09396968856, Performance = 0.022050159853637136, Fidelity = 0.9926496685528713\n",
      "Generation 452: Best Fitness = -72501.72168230335, Performance = 0.017289679671224453, Fidelity = 0.99274981054209\n",
      "Generation 453: Best Fitness = -80125.83243826401, Performance = 0.025815053947826086, Fidelity = 0.9919873909411197\n",
      "Generation 454: Best Fitness = -41978.886937788404, Performance = 0.00785347238303116, Fidelity = 0.9958021034527488\n",
      "Generation 455: Best Fitness = -68035.78545028564, Performance = 0.029696478046162773, Fidelity = 0.9931963917584934\n",
      "Generation 456: Best Fitness = -75614.37399977368, Performance = 0.020934288879599253, Fidelity = 0.9924385416657338\n",
      "Generation 457: Best Fitness = -61113.53649372033, Performance = 0.022154236732804627, Fidelity = 0.9938886241963912\n",
      "Generation 458: Best Fitness = -68673.7317377523, Performance = 0.025828004675998124, Fidelity = 0.9931326009982201\n",
      "Generation 459: Best Fitness = -62541.784143639, Performance = 0.025339316010009372, Fidelity = 0.9937457962463201\n",
      "Generation 460: Best Fitness = -62988.598653141606, Performance = 0.01820386234507338, Fidelity = 0.9937011219308235\n",
      "Generation 461: Best Fitness = -59435.88866493333, Performance = 0.026375734196054438, Fidelity = 0.9940563847577725\n",
      "Generation 462: Best Fitness = -52129.61837127543, Performance = 0.015582652231210897, Fidelity = 0.9947870225802202\n",
      "Generation 463: Best Fitness = -57061.407212961545, Performance = 0.01548836459590709, Fidelity = 0.9942938437903392\n",
      "Generation 464: Best Fitness = -57270.50201600577, Performance = 0.025531493035298336, Fidelity = 0.9942729242669064\n",
      "Generation 465: Best Fitness = -64160.51899428261, Performance = 0.02392641853915414, Fidelity = 0.9935839241741532\n",
      "Generation 466: Best Fitness = -64011.17944911749, Performance = 0.023880287270690987, Fidelity = 0.993598858174801\n",
      "Generation 467: Best Fitness = -79252.73636100168, Performance = 0.017156169278343243, Fidelity = 0.9920747092077306\n",
      "Generation 468: Best Fitness = -61909.54227838356, Performance = 0.02336160928751461, Fidelity = 0.9938090224105524\n",
      "Generation 469: Best Fitness = -64745.81379683116, Performance = 0.024419793779733204, Fidelity = 0.9935253942005231\n",
      "Generation 470: Best Fitness = -76434.82274269173, Performance = 0.020707143191247026, Fidelity = 0.9923564970185876\n",
      "Generation 471: Best Fitness = -81205.99954000968, Performance = 0.01876879005039608, Fidelity = 0.991879381277209\n",
      "Generation 472: Best Fitness = -77607.51380067733, Performance = 0.005543414703754496, Fidelity = 0.9922392430765176\n",
      "Generation 473: Best Fitness = -74074.89884334199, Performance = 0.023173033444821522, Fidelity = 0.9925924869426324\n",
      "Generation 474: Best Fitness = -67289.00486366439, Performance = 0.023176015541352825, Fidelity = 0.993271076337618\n",
      "Generation 475: Best Fitness = -73343.3937415207, Performance = 0.023991498449715213, Fidelity = 0.9926656366343495\n",
      "Generation 476: Best Fitness = -71202.20062512114, Performance = 0.02468784455006312, Fidelity = 0.9928797552496433\n",
      "Generation 477: Best Fitness = -69188.32783589028, Performance = 0.024370592696228394, Fidelity = 0.9930811428458183\n",
      "Generation 478: Best Fitness = -70065.41318852843, Performance = 0.019750459901639525, Fidelity = 0.9929934389306873\n",
      "Generation 479: Best Fitness = -60014.68329275782, Performance = 0.015917519358978015, Fidelity = 0.9939985157532049\n",
      "Generation 480: Best Fitness = -67776.19000118083, Performance = 0.01825549389642785, Fidelity = 0.993222362744388\n",
      "Generation 481: Best Fitness = -63871.4239196225, Performance = 0.02029890400431778, Fidelity = 0.9936128373091337\n",
      "Generation 482: Best Fitness = -80605.32201595439, Performance = 0.013419691113261965, Fidelity = 0.9919394543787134\n",
      "Generation 483: Best Fitness = -71910.39114047687, Performance = 0.021630309138342824, Fidelity = 0.9928089392556432\n",
      "Generation 484: Best Fitness = -81456.33550473757, Performance = 0.02105626568285453, Fidelity = 0.9918543453932606\n",
      "Generation 485: Best Fitness = -66062.95105301002, Performance = 0.022153297501456223, Fidelity = 0.9933936827414015\n",
      "Generation 486: Best Fitness = -62208.46154053462, Performance = 0.013901984152101525, Fidelity = 0.9937791399439624\n",
      "Generation 487: Best Fitness = -93056.78786414213, Performance = 0.02318878121214078, Fidelity = 0.9906942980248046\n",
      "Generation 488: Best Fitness = -65070.53408058544, Performance = 0.020552777396193083, Fidelity = 0.9934929260391641\n",
      "Generation 489: Best Fitness = -77824.17900207665, Performance = 0.02309941089248849, Fidelity = 0.9922175590003814\n",
      "Generation 490: Best Fitness = -68464.39411340079, Performance = 0.021971154704315033, Fidelity = 0.9931535386175052\n",
      "Generation 491: Best Fitness = -77120.79815424637, Performance = 0.026308709451344645, Fidelity = 0.9922878938758659\n",
      "Generation 492: Best Fitness = -60882.19893124401, Performance = 0.014892896317044678, Fidelity = 0.9939117652139793\n",
      "Generation 493: Best Fitness = -56869.439790122524, Performance = 0.021698666759860763, Fidelity = 0.994313034322321\n",
      "Generation 494: Best Fitness = -61203.190455059215, Performance = 0.02547877197725297, Fidelity = 0.9938796554757221\n",
      "Generation 495: Best Fitness = -66239.79374841416, Performance = 0.024366515772262273, Fidelity = 0.9933759962586428\n",
      "Generation 496: Best Fitness = -85600.96847228693, Performance = 0.025388852132111714, Fidelity = 0.9914398777639192\n",
      "Generation 497: Best Fitness = -68334.0683930039, Performance = 0.023528318907554902, Fidelity = 0.9931665696323807\n",
      "Generation 498: Best Fitness = -58815.24945400344, Performance = 0.016799529708291624, Fidelity = 0.99411845825507\n",
      "Generation 499: Best Fitness = -65362.314897503085, Performance = 0.025698937691037933, Fidelity = 0.993463742811312\n",
      "Generation 500: Best Fitness = -87431.90349724784, Performance = 0.02116837397503439, Fidelity = 0.9912567884819012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 25.59049385,  -5.43796247,   3.60220135,  -2.40719708,\n",
       "           3.82261704,  -8.37856576,  -0.21988188,   0.34130629,\n",
       "           7.40783522],\n",
       "        [  0.34693688,   5.63847369,   0.19685201,   9.41510656,\n",
       "          -0.77739962,  -1.47032505,   0.34632738,  -5.3162834 ,\n",
       "           1.55616257],\n",
       "        [  0.85626519,  -0.07800748, -23.24934382,  -0.25318446,\n",
       "           0.54265673, -11.42453276,  -2.76392074,  -6.02731853,\n",
       "          -4.368726  ],\n",
       "        [ -0.09047742,   5.67560055,   0.93608411,  -8.49087582,\n",
       "          -4.56440212,  -7.52664516,  11.74023344,   0.47133831,\n",
       "           9.37925092],\n",
       "        [ -0.12506459,   4.75008462,   0.51306787,  -2.0660361 ,\n",
       "          17.88204994,   1.7062149 ,  -5.61387328,  -4.58454737,\n",
       "          -3.89978063],\n",
       "        [ -0.7570048 ,  -1.53704519,  -1.00958121,  -4.42569784,\n",
       "           0.84685873,   9.15241854,   6.29298551,   0.60037314,\n",
       "          -1.61808421],\n",
       "        [ -1.9718201 ,   1.03703778,  -0.6173608 ,   3.6286028 ,\n",
       "           1.0211494 ,  -0.75131325,   2.4334466 ,   5.95631139,\n",
       "           1.83162979],\n",
       "        [ -2.54303233,   1.17674655,  -1.30149818,   2.39653929,\n",
       "           1.25288363,  -0.02904379,  -7.39596759,  -3.03427505,\n",
       "          -1.24747347],\n",
       "        [ -0.4945556 ,   1.92450574,   0.91236717,  -0.52830935,\n",
       "          -0.30063787,   2.44415197,   4.62051341,  -1.92538217,\n",
       "           2.5499258 ]]),\n",
       " -87431.90349724784)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's optimize the function evaluate_matrix respect to m\n",
    "# This is my first time ever to implement an advanced optimization algorithm to solve a real-world problem. I'm so excited! But please see if there is anything we an improve!\n",
    "# I chose genetic algorithm. Not sure if this is the best choice\n",
    "\n",
    "# Genetic Algorithm Components\n",
    "class GeneticAlgorithm:\n",
    "    def __init__(self, population_size, matrix_shape, mutation_rate, generations):\n",
    "        self.population_size = population_size\n",
    "        self.matrix_shape = matrix_shape\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.generations = generations\n",
    "        self.population = [np.random.rand(*matrix_shape) for _ in range(population_size)]\n",
    "    \n",
    "    def fitness(self, matrix):\n",
    "        a, b = evaluate_matrix(Matrix(matrix))\n",
    "        return 10 * a - 1e7 * (1 - b)  # Maximizing a, giving a large peanalty for b < 1\n",
    "    \n",
    "    def select(self):\n",
    "        # Simple tournament selection\n",
    "        selected = []\n",
    "        for _ in range(self.population_size):\n",
    "            i, j = np.random.randint(0, self.population_size, 2)\n",
    "            selected.append(self.population[i] if self.fitness(self.population[i]) > self.fitness(self.population[j]) else self.population[j])\n",
    "        return selected\n",
    "    \n",
    "    def crossover(self, parent1, parent2):\n",
    "        # Single point crossover\n",
    "        if np.random.rand() < 0.5:  # Swap parents to ensure diversity\n",
    "            parent1, parent2 = parent2, parent1\n",
    "        split = np.random.randint(1, np.prod(self.matrix_shape))\n",
    "        child1_flat = np.concatenate((parent1.flatten()[:split], parent2.flatten()[split:]))\n",
    "        child2_flat = np.concatenate((parent2.flatten()[:split], parent1.flatten()[split:]))\n",
    "        return child1_flat.reshape(self.matrix_shape), child2_flat.reshape(self.matrix_shape)\n",
    "    \n",
    "    def mutate(self, matrix):\n",
    "        # Random mutation\n",
    "        for i in range(matrix.shape[0]):\n",
    "            for j in range(matrix.shape[1]):\n",
    "                if np.random.rand() < self.mutation_rate:\n",
    "                    matrix[i, j] += np.random.normal(0, 1)\n",
    "        return matrix\n",
    "    \n",
    "    def evolve(self):\n",
    "        for generation in range(self.generations):\n",
    "            new_population = []\n",
    "            selected = self.select()\n",
    "            for i in range(0, self.population_size, 2):\n",
    "                parent1, parent2 = selected[i], selected[i+1]\n",
    "                child1, child2 = self.crossover(parent1, parent2)\n",
    "                new_population.append(self.mutate(child1))\n",
    "                new_population.append(self.mutate(child2))\n",
    "            self.population = new_population\n",
    "            # Optional: Print best fitness in generation\n",
    "            best_fitness = max(self.fitness(matrix) for matrix in self.population)\n",
    "            good_matrix = max(self.population, key=self.fitness)\n",
    "            p, f = evaluate_matrix(Matrix(good_matrix))\n",
    "            print(f\"Generation {generation+1}: Best Fitness = {best_fitness}, Performance = {p}, Fidelity = {f}\")\n",
    "        return self.best_solution()\n",
    "    \n",
    "    def best_solution(self):\n",
    "        best_matrix = max(self.population, key=self.fitness)\n",
    "        return best_matrix, self.fitness(best_matrix)\n",
    "\n",
    "# Parameters for the GA\n",
    "population_size = 100\n",
    "dim = 9\n",
    "matrix_shape = (dim, dim)  # Example matrix shape\n",
    "mutation_rate = 0.05\n",
    "generations = 500\n",
    "\n",
    "# Initialize and run the GA\n",
    "ga = GeneticAlgorithm(population_size, matrix_shape, mutation_rate, generations)\n",
    "best_matrix, best_fitness = ga.evolve()\n",
    "\n",
    "best_matrix, best_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
